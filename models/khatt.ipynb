{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-06-28T20:03:00.219820Z",
          "iopub.execute_input": "2022-06-28T20:03:00.220287Z",
          "iopub.status.idle": "2022-06-28T20:03:00.243897Z",
          "shell.execute_reply.started": "2022-06-28T20:03:00.220194Z",
          "shell.execute_reply": "2022-06-28T20:03:00.243063Z"
        },
        "trusted": true,
        "id": "rD8D0YSC6sJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install"
      ],
      "metadata": {
        "id": "d27V4-oI64wQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric, load_dataset\n",
        "import torch\n",
        "from transformers import (\n",
        "    TrOCRProcessor,\n",
        "    AutoFeatureExtractor,\n",
        "    AutoTokenizer,\n",
        "    VisionEncoderDecoderModel,\n",
        "    Seq2SeqTrainer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    default_data_collator,\n",
        "    HfArgumentParser,\n",
        ")\n",
        "import wandb\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-28T20:03:00.258734Z",
          "iopub.execute_input": "2022-06-28T20:03:00.258972Z",
          "iopub.status.idle": "2022-06-28T20:03:08.061851Z",
          "shell.execute_reply.started": "2022-06-28T20:03:00.258950Z",
          "shell.execute_reply": "2022-06-28T20:03:08.060646Z"
        },
        "trusted": true,
        "id": "50IV2stH6sJI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OCRDataset(Dataset):\n",
        "    def __init__(self, df, processor, transforms=lambda x:x, max_target_length=128):\n",
        "        self.df = df\n",
        "        self.processor = processor\n",
        "        self.transforms = transforms\n",
        "        self.max_target_length = max_target_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # get file name + text\n",
        "        #file_name = self.df['file_name'][idx]\n",
        "        text = self.df['text'][idx]\n",
        "        # prepare image (i.e. resize + normalize)\n",
        "        image = self.df['image'][idx].convert(\"RGB\")\n",
        "        image = self.transforms(image)\n",
        "        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n",
        "        # add labels (input_ids) by encoding the text\n",
        "        labels = self.processor.tokenizer(text,\n",
        "                                          padding=\"max_length\",\n",
        "                                          max_length=self.max_target_length).input_ids\n",
        "        # important: make sure that PAD tokens are ignored by the loss function\n",
        "        labels = [label if label != self.processor.tokenizer.pad_token_id else -100 for label in labels]\n",
        "\n",
        "        encoding = {\"pixel_values\": pixel_values.squeeze(), \"labels\": torch.tensor(labels)}\n",
        "        return encoding"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-28T20:03:08.064474Z",
          "iopub.execute_input": "2022-06-28T20:03:08.065544Z",
          "iopub.status.idle": "2022-06-28T20:03:08.077465Z",
          "shell.execute_reply.started": "2022-06-28T20:03:08.065504Z",
          "shell.execute_reply": "2022-06-28T20:03:08.076505Z"
        },
        "trusted": true,
        "id": "k1eUyM506sJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = \"facebook/deit-base-distilled-patch16-384\"\n",
        "decoder = \"asafaya/bert-base-arabic\"\n",
        "model_name = \"microsoft/trocr-small-handwritten\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-28T20:03:08.078930Z",
          "iopub.execute_input": "2022-06-28T20:03:08.079395Z",
          "iopub.status.idle": "2022-06-28T20:03:08.093929Z",
          "shell.execute_reply.started": "2022-06-28T20:03:08.079351Z",
          "shell.execute_reply": "2022-06-28T20:03:08.092950Z"
        },
        "trusted": true,
        "id": "hY63xeoH6sJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "        predict_with_generate=True,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        logging_strategy=\"epoch\",\n",
        "        per_device_train_batch_size= 8, #train_args.per_device_train_batch_size,\n",
        "        per_device_eval_batch_size= 8, #train_args.per_device_eval_batch_size,\n",
        "        fp16=True,\n",
        "        adam_beta1=0.9,\n",
        "        adam_beta2=0.98,\n",
        "        adam_epsilon=1e-08,\n",
        "        num_train_epochs=10, #train_args.num_train_epochs,\n",
        "        weight_decay=0.005,\n",
        "        learning_rate=5e-5, #train_args.learning_rate,\n",
        "        seed=42,\n",
        "        report_to=\"wandb\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"cer\",\n",
        "        do_train=True,\n",
        "        do_eval=True,\n",
        "        do_predict=True,\n",
        "        output_dir = \"./\"#train_args.output_dir,\n",
        "    )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-28T20:03:08.097909Z",
          "iopub.execute_input": "2022-06-28T20:03:08.098211Z",
          "iopub.status.idle": "2022-06-28T20:03:08.162191Z",
          "shell.execute_reply.started": "2022-06-28T20:03:08.098176Z",
          "shell.execute_reply": "2022-06-28T20:03:08.161192Z"
        },
        "trusted": true,
        "id": "Vh5OXOw36sJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\n",
        "        \"gagan3012/OnlineKhatt\"\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-28T20:03:08.163578Z",
          "iopub.execute_input": "2022-06-28T20:03:08.163938Z"
        },
        "trusted": true,
        "id": "_ZUVwmNx6sJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if model_name is None:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(decoder)\n",
        "    feature_extractor = AutoFeatureExtractor.from_pretrained(encoder)\n",
        "    processor = TrOCRProcessor(feature_extractor, tokenizer)\n",
        "    model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(encoder, decoder)\n",
        "\n",
        "else:\n",
        "    processor = TrOCRProcessor.from_pretrained(model_name)\n",
        "    model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(\n",
        "        encoder, decoder)\n",
        "\n",
        "    #fn_kwargs = dict(\n",
        "    #    processor = processor,\n",
        "    #)\n",
        "    #df = dataset.map(preprocess,fn_kwargs=fn_kwargs,remove_columns=[\"id\"])\n",
        "\n",
        "df_train = pd.DataFrame(dataset['train'])\n",
        "df_eval = pd.DataFrame(dataset['dev'])\n",
        "df_pred = pd.DataFrame(dataset['test'])\n",
        "\n",
        "df_train = df_train.sample(frac=1)\n",
        "df_eval = df_eval.sample(frac=1)\n",
        "df_pred = df_pred.sample(frac=1)\n",
        "\n",
        "transformer = lambda x: x\n",
        "\n",
        "train_dataset = OCRDataset(df=df_train,\n",
        "                           processor=processor,\n",
        "                           max_target_length=128,\n",
        "                           transforms=transformer)\n",
        "\n",
        "eval_dataset = OCRDataset(df=df_eval,\n",
        "                          processor=processor,\n",
        "                          max_target_length=128,\n",
        "                          transforms=transformer)\n",
        "\n",
        "predict_dataset = OCRDataset(df=df_pred,\n",
        "                             processor=processor,\n",
        "                             max_target_length=128,\n",
        "                             transforms=transformer)\n",
        "\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Eval dataset size: {len(eval_dataset)}\")\n",
        "print(f\"Predict dataset size: {len(predict_dataset)}\")\n",
        "\n",
        "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
        "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
        "# make sure vocab size is set correctly\n",
        "model.config.vocab_size = model.config.decoder.vocab_size\n",
        "\n",
        "# set beam search parameters\n",
        "model.config.eos_token_id = processor.tokenizer.sep_token_id\n",
        "model.config.max_length = 64\n",
        "model.config.early_stopping = True\n",
        "model.config.no_repeat_ngram_size = 3\n",
        "model.config.length_penalty = 2.0\n",
        "model.config.num_beams = 4"
      ],
      "metadata": {
        "trusted": true,
        "id": "PPPZz6nw6sJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer"
      ],
      "metadata": {
        "trusted": true,
        "id": "bFRi2S3R6sJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cer_metric = load_metric(\"cer\")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels_ids = pred.label_ids\n",
        "    pred_ids = pred.predictions\n",
        "\n",
        "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    labels_ids[labels_ids == -100] = processor.tokenizer.pad_token_id\n",
        "    label_str = processor.batch_decode(labels_ids, skip_special_tokens=True)\n",
        "\n",
        "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    return {\"cer\": cer}"
      ],
      "metadata": {
        "trusted": true,
        "id": "hHuRHp8-6sJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "        model=model,\n",
        "        tokenizer=processor.feature_extractor,\n",
        "        args=training_args,\n",
        "        compute_metrics=compute_metrics,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "        data_collator=default_data_collator,\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "SxYFdfK_6sJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training model\")\n",
        "train_result = trainer.train()\n",
        "metrics = train_result.metrics\n",
        "trainer.log_metrics(\"train\", metrics)\n",
        "trainer.save_metrics(\"train\", metrics)\n",
        "trainer.save_state()\n",
        "print(\"Evaluating model\")\n",
        "metrics = trainer.evaluate(metric_key_prefix=\"eval\")\n",
        "trainer.log_metrics(\"eval\", metrics)\n",
        "trainer.save_metrics(\"eval\", metrics)\n",
        "print(\"Predicting\")\n",
        "predict_results = trainer.predict(\n",
        "    predict_dataset,\n",
        "    metric_key_prefix=\"predict\",\n",
        ")\n",
        "metrics = predict_results.metrics\n",
        "max_predict_samples = (\n",
        "    data_args.max_predict_samples\n",
        "    if data_args.max_predict_samples is not None\n",
        "    else len(predict_dataset)\n",
        ")\n",
        "metrics[\"predict_samples\"] = min(max_predict_samples, len(predict_dataset))\n",
        "\n",
        "trainer.log_metrics(\"predict\", metrics)\n",
        "trainer.save_metrics(\"predict\", metrics)\n",
        "\n",
        "if trainer.is_world_process_zero():\n",
        "    if training_args.predict_with_generate:\n",
        "        predictions = processor.batch_decode(\n",
        "            predict_results.predictions,\n",
        "            skip_special_tokens=True,\n",
        "            clean_up_tokenization_spaces=True,\n",
        "        )\n",
        "        predictions = [pred.strip() for pred in predictions]\n",
        "        output_prediction_file = os.path.join(\n",
        "            model_args.save_dir, \"generated_predictions.txt\"\n",
        "        )\n",
        "        print(predictions)\n",
        "        with open(output_prediction_file, \"w\") as writer:\n",
        "            writer.write(\"\\n\".join(predictions))"
      ],
      "metadata": {
        "trusted": true,
        "id": "7HhIL2YS6sJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0f_FcZ9D6sJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bN2KkDj66sJQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}