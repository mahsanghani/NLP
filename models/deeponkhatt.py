# -*- coding: utf-8 -*-
"""DeepOnKHATT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZD7d6vrRnoEWK8FsXgFur6lf35qPgOZL

---
**NOTE** \
After installing tensorflow 1.5, you need to restart runtime. You will be asked to do so by clicking button upon installation completion.
This notebook is developed to run on Colab.
---
"""

!pip3 install tensorflow==1.15.0

import tensorflow as tf
print(tf.__version__)

!git clone https://github.com/fakhralwajih/DeepOnKHATT.git

# change dir to DeepOnKHATT dir
import os
os.chdir('DeepOnKHATT')

#download pre-trained models
!gdown --id 1-YAltfi_4Klvu_-f72iSkHboM46-iH_t --output lm/trie
!gdown --id 1MqhnAcXMwT_nq_z-01CRhWKLYJYZBa1A --output lm/lm.binary
!gdown --id  1Z_gzzWVjskv_1JqErGuz8ZVfCSNaC3VY --output models/models.zip
!unzip models/models.zip -d models/

#install decoder 
!pip3 install ds_ctcdecoder==0.6.1

from features.feature import calculate_feature_vector_sequence 
from features.preprocessing import preprocess_handwriting
from rnn import BiRNN as BiRNN_model
from datasets import pad_sequences,sparse_tuple_from ,handwriting_to_input_vector

import argparse
import numpy as np
import tensorflow as tf
from ds_ctcdecoder import ctc_beam_search_decoder, Scorer
from text import Alphabet,get_arabic_letters,decodex

letters_ar=get_arabic_letters()
alphabet = Alphabet('alphabet.txt')
#convert this to funcation
mapping={}
with open('arabic_mapping.txt','r', encoding='utf-8') as inf:
    for line in inf:
        key,val=line.split('\t')
        mapping[key]=val.strip()
mapping[' ']=' '

"""## imports for writing canvas"""

from IPython.display import HTML, Image
from google.colab.output import eval_js
from base64 import b64decode

from configparser import ConfigParser
config_file='neural_network.ini'
model_path='models/model.ckpt-14'
parser = ConfigParser()

parser.read('neural_network.ini')
config_header='nn'       
network_type = parser.get(config_header , 'network_type')
n_context = parser.getint(config_header, 'n_context') 
n_input = parser.getint(config_header, 'n_input')
beam_search_decoder = parser.get(config_header, 'beam_search_decoder')

#LM setting
config_header='lm' 
lm_alpha=parser.getfloat(config_header , 'lm_alpha')
lm_beta=parser.getfloat(config_header , 'lm_beta')
beam_width=parser.getint(config_header , 'beam_width')
cutoff_prob=parser.getfloat(config_header , 'cutoff_prob')
cutoff_top_n= parser.getint(config_header , 'cutoff_top_n')

conf_path='neural_network.ini'
input_tensor = tf.placeholder(tf.float32, [None, None, n_input + (2 * n_input * n_context)], name='input')    
seq_length = tf.placeholder(tf.int32, [None], name='seq_length')
logits, summary_op = BiRNN_model(conf_path,input_tensor,tf.to_int64(seq_length),n_input,n_context)
#if you need to try greedy decoder without LM
# decoded, log_prob = ctc_ops.ctc_greedy_decoder(logits, seq_length, merge_repeated=True)

lm_binary_path='lm/lm.binary'
lm_trie_path='lm/trie'

scorer=None
scorer = Scorer(lm_alpha, lm_beta,lm_binary_path, lm_trie_path,alphabet)

config_file='neural_network.ini'

saver = tf.train.Saver()
# create the session
sess = tf.Session()
saver.restore(sess, 'models/model.ckpt-14')
print('Model restored')

canvas_html = """
<canvas id="mycanvas" width=%d height=%d style="border:1px solid #000000;"></canvas>
 <br />
<button>Recoginize</button>

<script>
var canvas = document.getElementById('mycanvas')
var ctx = canvas.getContext('2d')
ctx.lineWidth = %d
ctx.canvas.style.touchAction = "none";
var button = document.querySelector('button')
var mouse = {x: 0, y: 0}
var points=[]

canvas.addEventListener('pointermove', function(e) {
  mouse.x = e.pageX - this.offsetLeft
  mouse.y = e.pageY - this.offsetTop
})
canvas.onpointerdown = ()=>{
  ctx.beginPath()
  ctx.moveTo(mouse.x, mouse.y)
  
  canvas.addEventListener('pointermove', onPaint)
}
canvas.onpointerup = ()=>{
  canvas.removeEventListener('pointermove', onPaint)
  points.pop()
  points.push([mouse.x,mouse.y,1])
}
var onPaint = ()=>{
  ctx.lineTo(mouse.x, mouse.y)
  ctx.stroke()
  points.push([mouse.x,mouse.y,0])
}
var data = new Promise(resolve=>{
  button.onclick = ()=>{
    resolve(canvas.toDataURL('image/png'))
  }
})
</script>
"""
def draw(filename='drawing.png', w=900, h=200, line_width=1):
  display(HTML(canvas_html % (w, h, line_width)))
  data = eval_js("data")
  points=eval_js("points")
  # strokes = Utils.Rearrange(strokes, 20);
  points=np.array(points)

  # points=rearrange(points)


  # print("Points before pre",points.shape)
  NORM_ARGS = ["origin","filp_h","smooth", "slope", "resample", "slant", "height"]
  FEAT_ARGS = ["x_cor","y_cor","penup","dir", "curv", "vic_aspect", "vic_curl", "vic_line", "vic_slope", "bitmap"]
  # print("Normalizing trajectory...")
  traj = preprocess_handwriting(points, NORM_ARGS)
  # print(traj)
  # print("Calculating feature vector sequence...")
  feat_seq_mat = calculate_feature_vector_sequence(traj, FEAT_ARGS)
  feat_seq_mat=feat_seq_mat.astype('float32')
  feat_seq_mat.shape

  data = []

  train_input=handwriting_to_input_vector(feat_seq_mat,20,9)
  train_input = train_input.astype('float32')

  data.append(train_input)
  # data_len

  data = np.asarray(data)
  # data_len = np.asarray(train_input)


  # Pad input to max_time_step of this batch
  source, source_lengths = pad_sequences(data)
  my_logits=sess.run(logits, feed_dict={
                  input_tensor: source,                    
                  seq_length: source_lengths}
              )
  my_logits = np.squeeze(my_logits)
  maxT, _ = my_logits.shape # dim0=t, dim1=c
	
            # apply softmax
  res = np.zeros(my_logits.shape)
  for t in range(maxT):
      y = my_logits[t, :]
      e = np.exp(y)
      s = np.sum(e)
      res[t, :] = e / s
            
  decoded = ctc_beam_search_decoder(res, alphabet, beam_width,
                                  scorer=scorer, cutoff_prob=cutoff_prob,
                                  cutoff_top_n=cutoff_top_n)

  print("Result : "+decodex(decoded[0][1],mapping))

"""**Note**  \
The next cell, you can run multiple times as you wish. You may want to write many samples. \
All the above cells should run only once. \

Run the cell and write on the canvas while the cell is running. Then, click on "Recoginize" button to get the recognition result.

"""

draw()

"""The above canvas was tested on PC mouse and S pen (samsung tablet) and works well with S pen."""