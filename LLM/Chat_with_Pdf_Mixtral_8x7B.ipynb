{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efz83OboW1lU"
      },
      "source": [
        "\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/drive/1rH8df-C3P9pL4yrC2qSae9IOtx5Mr1N_\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" width=\"200\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mixtral-8x7B-Instruct-v0.1 + Haystack: build RAG pipelines🤘\n",
        "\n",
        "###  Retrieval Augmented Generation pipeline , using the new powerful [Mixtral-8x7B-Instruct-v0.1](https://huggingface.co/blog/mixtral/) and [Haystack](https://github.com/deepset-ai/haystack) LLM orchestration framework.\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://codeandhack.com/wp-content/uploads/2023/12/Mixtral-8x7B-SMoE-Model.jpeg\" width=\"270\" style=\"display:inline;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img src=\"https://img.freepik.com/premium-vector/electric-guitar-fire-hot-rock-music-guitar-flames-hard-rock-rock-roll-concert-festival-label-night-club-live-show-vector-logo-emblem_570429-23178.jpg?w=2000\" width=\"180\"><img src=\"https://haystack.deepset.ai/images/haystack-ogimage.png\" width=\"360\" style=\"display:inline;\">"
      ],
      "metadata": {
        "id": "56jUIjtnfClE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd0Gzp3xODYw"
      },
      "source": [
        "#Importante! 🚨\n",
        "\n",
        "Per eseguire questo notebook su Colab, è necessario disporre di un token API Hugging Face. Segui questi passaggi per ottenerlo:\n",
        "\n",
        "1. Crea un account su [Hugging Face](https://huggingface.co/).\n",
        "2. Accedi alle impostazioni del tuo account: [https://huggingface.co/settings](https://huggingface.co/settings/tokens?new_token=true).\n",
        "3. Nella sezione \"API Tokens\", crea un nuovo token selezionando \"New Token\" e assegnandogli un nome. Assicurati di selezionare Rule \"read\".\n",
        "\n",
        "Una volta ottenuto il tuo token, puoi inserirlo nel notebook per autenticarti con l'API Hugging Face e accedere alle risorse necessarie.\n",
        "\n",
        "Grazie per la tua collaborazione e buon lavoro con il notebook! 🌟💻\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZv5h30axwwl"
      },
      "source": [
        "# Installazione del Pacchetto farm-haystack: 🚀\n",
        "\n",
        "Nel blocco di codice seguente, stiamo per fare qualcosa di emozionante! 🎉\n",
        "\n",
        "1. `%%capture`: Questo comando magico cattura l'output della cella, mantenendo il nostro notebook pulito e ordinato. Nessun caos visivo qui! 🧹\n",
        "\n",
        "2. `!pip install farm-haystack`: Con questo comando stiamo aprendo le porte alla potenza di `farm-haystack`! 🌐 Assicurati di tenere gli occhi sulla barra di avanzamento, stiamo per rendere il nostro ambiente pronto per l'avventura! ⚙️\n",
        "\n",
        "Questo è solo l'inizio! Assicuriamoci che tutto sia a posto e poi immergiamoci nel magico mondo del nostro progetto! 💻✨\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "elvzyj3L1dcV",
        "outputId": "7175866b-6deb-4a99-c114-fd9d92630b25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting farm-haystack[colab]\n",
            "  Downloading farm_haystack-1.22.1-py3-none-any.whl (856 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.0/856.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boilerpy3 (from farm-haystack[colab])\n",
            "  Downloading boilerpy3-1.0.7-py3-none-any.whl (22 kB)\n",
            "Collecting events (from farm-haystack[colab])\n",
            "  Downloading Events-0.5-py3-none-any.whl (6.8 kB)\n",
            "Collecting httpx (from farm-haystack[colab])\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (4.19.2)\n",
            "Collecting lazy-imports==0.3.1 (from farm-haystack[colab])\n",
            "  Downloading lazy_imports-0.3.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (10.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (3.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (9.4.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (4.1.0)\n",
            "Collecting posthog (from farm-haystack[colab])\n",
            "  Downloading posthog-3.1.0-py2.py3-none-any.whl (37 kB)\n",
            "Collecting prompthub-py==4.0.0 (from farm-haystack[colab])\n",
            "  Downloading prompthub_py-4.0.0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: pydantic<2 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (1.10.13)\n",
            "Collecting quantulum3 (from farm-haystack[colab])\n",
            "  Downloading quantulum3-0.9.0-py3-none-any.whl (10.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rank-bm25 (from farm-haystack[colab])\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (2.31.0)\n",
            "Collecting requests-cache<1.0.0 (from farm-haystack[colab])\n",
            "  Downloading requests_cache-0.9.8-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.7/48.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn>=1.3.0 (from farm-haystack[colab])\n",
            "  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sseclient-py (from farm-haystack[colab])\n",
            "  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (8.2.3)\n",
            "Collecting tiktoken>=0.5.1 (from farm-haystack[colab])\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab]) (4.66.1)\n",
            "Collecting transformers==4.34.1 (from farm-haystack[colab])\n",
            "  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow (from farm-haystack[colab])\n",
            "  Downloading Pillow-9.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from prompthub-py==4.0.0->farm-haystack[colab]) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack[colab]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack[colab]) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack[colab]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack[colab]) (23.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack[colab]) (2023.6.3)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers==4.34.1->farm-haystack[colab])\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->farm-haystack[colab]) (0.4.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2->farm-haystack[colab]) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab]) (2023.11.17)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[colab]) (1.4.4)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[colab]) (23.1.0)\n",
            "Collecting cattrs>=22.2 (from requests-cache<1.0.0->farm-haystack[colab])\n",
            "  Downloading cattrs-23.2.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting url-normalize>=1.4 (from requests-cache<1.0.0->farm-haystack[colab])\n",
            "  Downloading url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack[colab]) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack[colab]) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack[colab]) (3.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack[colab]) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx->farm-haystack[colab])\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack[colab]) (1.3.0)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->farm-haystack[colab])\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[colab]) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[colab]) (0.31.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[colab]) (0.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->farm-haystack[colab]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->farm-haystack[colab]) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog->farm-haystack[colab]) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog->farm-haystack[colab])\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog->farm-haystack[colab])\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from quantulum3->farm-haystack[colab]) (7.0.0)\n",
            "Collecting num2words (from quantulum3->farm-haystack[colab])\n",
            "  Downloading num2words-0.5.13-py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests-cache<1.0.0->farm-haystack[colab]) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.1->farm-haystack[colab]) (2023.6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.34.1->farm-haystack[colab])\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docopt>=0.6.2 (from num2words->quantulum3->farm-haystack[colab])\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=80cfd5a2bab97df22647c6acbc83dca49ef2152110afd0955db1f2894f34ec17\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built docopt\n",
            "Installing collected packages: sseclient-py, monotonic, events, docopt, url-normalize, rank-bm25, pillow, num2words, lazy-imports, h11, cattrs, boilerpy3, backoff, tiktoken, scikit-learn, requests-cache, prompthub-py, posthog, huggingface-hub, httpcore, tokenizers, quantulum3, httpx, transformers, farm-haystack\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.19.4\n",
            "    Uninstalling huggingface-hub-0.19.4:\n",
            "      Successfully uninstalled huggingface-hub-0.19.4\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.0\n",
            "    Uninstalling tokenizers-0.15.0:\n",
            "      Successfully uninstalled tokenizers-0.15.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 boilerpy3-1.0.7 cattrs-23.2.3 docopt-0.6.2 events-0.5 farm-haystack-1.22.1 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 huggingface-hub-0.17.3 lazy-imports-0.3.1 monotonic-1.6 num2words-0.5.13 pillow-9.0.0 posthog-3.1.0 prompthub-py-4.0.0 quantulum3-0.9.0 rank-bm25-0.2.2 requests-cache-0.9.8 scikit-learn-1.3.2 sseclient-py-1.8.0 tiktoken-0.5.2 tokenizers-0.14.1 transformers-4.34.1 url-normalize-1.4.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#%%capture\n",
        "\n",
        "!pip install farm-haystack[colab]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCAYDd7NLCJc"
      },
      "source": [
        "# Richiesta del Token Hugging Face: 🔐🌐\n",
        "\n",
        "È il momento di collegare tutto! Nel codice seguente:\n",
        "\n",
        "1. **Richiesta del Token Hugging Face:** Utilizziamo `getpass` per in modo sicuro e interattivo acquisire il tuo token Hugging Face. 🤐🔑\n",
        "\n",
        "   - `HF_TOKEN = getpass(\"Il Tuo Hugging Face Token\")`: Chiediamo il token Hugging Face e lo immagazziniamo in `HF_TOKEN`, mantenendo la tua chiave segreta al sicuro. 🚀\n",
        "\n",
        "Questo è il passo chiave per sbloccare tutte le potenzialità di Hugging Face nel tuo progetto! 🌟🔓"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ4tvE-hKarh",
        "outputId": "90cbbccb-3837-4bfd-85e6-fe700468575d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Il Tuo Hugging Face Token··········\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "HF_TOKEN = getpass(\"Il Tuo Hugging Face Token\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSVy9VRRQSbk"
      },
      "source": [
        "##INSERISCI Il Tuo Hugging Face Token nella cellula rettangolare e premi Invio sulla tastiera."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsH7sSlzlVIa"
      },
      "source": [
        "# Importazione di Classi Haystack: 🌾📘\n",
        "\n",
        "Stiamo aggiungendo le carte vincenti al nostro mazzo! Nel codice seguente:\n",
        "\n",
        "1. **Import di `PreProcessor`:** Con `from haystack.nodes import PreProcessor`, otteniamo funzionalità di pre-elaborazione per preparare i nostri dati. [Preprocessor](https://docs.haystack.deepset.ai/docs/preprocessor) 🛠️📝\n",
        "\n",
        "2. **Import di `PromptModel`:** `from haystack.nodes import PromptModel` ci dà accesso alle funzioni del modello di prompt. Pronti per guidare il nostro modello! 🚗🤖\n",
        "\n",
        "3. **Import di `PromptTemplate`:** `from haystack.nodes import PromptTemplate` ci fornisce la flessibilità di definire modelli di prompt personalizzati. Stiamo dando forma al nostro stile! 🎨📄\n",
        "\n",
        "Siamo pronti a combinare queste classi per creare un flusso di lavoro potente con Haystack! 🚀🌾\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Spblp58SW0nH"
      },
      "outputs": [],
      "source": [
        "from haystack.nodes import PreProcessor,PromptModel, PromptTemplate, PromptNode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PE_NlaaR8Bh"
      },
      "source": [
        "# Avviso Importante: Scarica la Brochure! 📄🚨\n",
        "\n",
        "Per ottenere u dettagli e informazioni sulla nostra iniziativa, ti invitiamo a scaricare la brochure ufficiale.\n",
        "\n",
        "📥 [Scarica la Brochure Qui](https://drive.google.com/file/d/1tOs9VPiGrcgyEd8U4K2m-Ipx4xY4DPEl/view?usp=sharing)\n",
        "\n",
        "La brochure contiene dettagli importanti sul Master, le sue iniziative e come puoi unirti a noi per esplorare il mondo della Generative AI.\n",
        "La Brochure é in Pdf e sará la Base per istruire il nostro ChatBot. Buona lettura! 🌐📘\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI9Qvh6_4_o4"
      },
      "source": [
        "# Caricamento della Brochure \"Gen-AI Lab\": 📄🚀\n",
        "\n",
        "Ecco come far entrare la nostra brochure nel Gen-AI Lab! Nel codice seguente:\n",
        "\n",
        "1. **Import da Google Colab:** Utilizziamo `from google.colab import files` per sfruttare le funzionalità di caricamento di file di Colab. 🌐\n",
        "\n",
        "2. **Caricamento della Brochure:** Clicca sul pulsante \"Scegli Archivio\" e seleziona il percorso dove hai precedentemente scaricato la brochure. Il tuo prezioso documento PDF è pronto per il nostro Laboratorio! 📁💻\n",
        "\n",
        "   - **Specifica Chiara:** Assicurati di indicare agli utenti di cliccare sul pulsante \"Scegli Archivio\" per selezionare il percorso del file PDF della brochure. 🖱️📄\n",
        "\n",
        "Questo passo guida gli utenti attraverso il processo, assicurandoci che la brochure giunga al Gen-AI Lab in modo impeccabile! 🌈✨\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTpRgibStZ-K"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KXJjUqE6ed7"
      },
      "source": [
        "# Installazione di PyPDF2: 📄🔧\n",
        "\n",
        "Prepariamoci ad esplorare i segreti dei PDF! Nel codice seguente:\n",
        "\n",
        "1. **Installazione di PyPDF2:** Con `!pip install PyPDF2`, stiamo aggiungendo la libreria PyPDF2 al nostro ambiente. Siamo pronti a manipolare i nostri documenti PDF in grande stile! 🚀💼\n",
        "\n",
        "   - **Attenzione alla Sintassi:** Assicuriamoci di utilizzare la sintassi corretta per installare la libreria. 🔍⚙️\n",
        "\n",
        "Questo è il passo iniziale per sbloccare il potenziale di manipolazione dei PDF nel nostro progetto! 🌐✨\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYINJiGcsAxL"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install PyPDF2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okHLqQp96iOd"
      },
      "source": [
        "# Estrazione del Testo da un PDF e Creazione di un Documento Haystack: 📄🚀\n",
        "\n",
        "Stiamo per immergerci nel testo della nostra preziosa brochure del Gen-Ai LAB e creare un documento Haystack! Nel codice seguente:\n",
        "\n",
        "1. **Import di PyPDF2:** Con `import PyPDF2`, stiamo portando la potenza di PyPDF2 per manipolare i nostri documenti PDF. 📄🔍\n",
        "\n",
        "2. **Definizione del Percorso del PDF:** Specifica il percorso del tuo file PDF nel tuo ambiente con `pdf_file_path`. 🔗📂\n",
        "\n",
        "3. **Funzione di Estrazione del Testo:** Con `extract_text_from_pdf`, creiamo una funzione per estrarre il testo dal PDF. Stiamo per svelare i segreti del documento! 🕵️‍♂️💬\n",
        "\n",
        "4. **Loop sulle Pagine del PDF:** Attraverso un ciclo su tutte le pagine del PDF, estraiamo il testo da ciascuna pagina. Il nostro documento sta prendendo forma! 🔄🌐\n",
        "\n",
        "5. **Creazione del Documento Haystack:** Con il testo estratto, creiamo un documento Haystack con `Document`. Siamo pronti per esplorare il nostro testo nel mondo di Haystack! 🚀📄\n",
        "\n",
        "Questo è il nostro biglietto d'ingresso per esplorare il contenuto della brochure nel nostro progetto! 🌈✨\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-U3aInjv-Bo_"
      },
      "outputs": [],
      "source": [
        "import PyPDF2\n",
        "from haystack import Document\n",
        "\n",
        "pdf_file_path = \"Gen-Ai LAB Brochure.pdf\"  # Sostituisci con il percorso del tuo file PDF\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with open(pdf_path, \"rb\") as pdf_file:\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            page = pdf_reader.pages[page_num]\n",
        "            text += page.extract_text()\n",
        "\n",
        "    return text\n",
        "\n",
        "pdf_text = extract_text_from_pdf(pdf_file_path)\n",
        "\n",
        "# Creazione del documento di Haystack\n",
        "doc = Document(\n",
        "    content=pdf_text,\n",
        "    meta={\"pdf_path\": pdf_file_path}\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pF0nz0Wg7l_C"
      },
      "source": [
        "# Creazione di una Lista di Documenti e Pre-elaborazione: 📄🚀\n",
        "\n",
        "Stiamo portando il nostro documento nella fase di pre-elaborazione! Nel codice seguente:\n",
        "\n",
        "1. **Creazione di una Lista di Documenti:** Con `docs = [doc]`, stiamo creando una lista contenente il nostro singolo documento. Il nostro prezioso contenuto è ora racchiuso in una lista! 📋💼\n",
        "\n",
        "2. **Inizializzazione del PreProcessor:** Con `processor = PreProcessor(...)`, stiamo configurando il nostro pre-elaboratore per preparare i documenti al meglio. 🛠️✨\n",
        "\n",
        "   - **Parametri Chiave:**\n",
        "     - `clean_empty_lines`: Rimuoviamo le linee vuote per una pulizia ottimale. 🧹\n",
        "     - `clean_whitespace`: Eliminiamo gli spazi vuoti per una presentazione impeccabile. 🚀\n",
        "     - `clean_header_footer`: Trattiamo gli eventuali elementi di intestazione e piè di pagina. 📑\n",
        "     - `split_by`: Suddividiamo il testo per parola. 📊\n",
        "     - `split_length`: Impostiamo la lunghezza di suddivisione a 500 parole. 📏\n",
        "     - `split_respect_sentence_boundary`: Rispettiamo i limiti delle frasi durante la suddivisione. 🗣️\n",
        "     - `split_overlap`: Nessun sovrapposizione durante la suddivisione. 🚫\n",
        "     - `language`: Specifichiamo la lingua italiana. 🇮🇹\n",
        "\n",
        "3. **Processamento della Lista di Documenti:** Con `preprocessed_docs = processor.process(docs)`, stiamo applicando il nostro pre-elaboratore alla lista di documenti. I documenti stanno per essere ottimizzati e pronti per la fase successiva! 🔄🚀\n",
        "\n",
        "Questo è il nostro passo per garantire che i nostri documenti siano nel miglior stato possibile per le successive fasi del nostro progetto! 🌈✨\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gZh5nXkmY1S",
        "outputId": "6119e089-af16-4451-bd14-3f30e31a0515"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Preprocessing: 100%|██████████| 1/1 [00:00<00:00, 18.76docs/s]\n"
          ]
        }
      ],
      "source": [
        "# Crea una lista contenente il tuo singolo documento\n",
        "docs = [doc]\n",
        "\n",
        "processor = PreProcessor(\n",
        "    clean_empty_lines=True,\n",
        "    clean_whitespace=True,\n",
        "    clean_header_footer=True,\n",
        "    split_by=\"word\",\n",
        "    split_length=500,\n",
        "    split_respect_sentence_boundary=True,\n",
        "    split_overlap=0,\n",
        "    language=\"it\",\n",
        ")\n",
        "\n",
        "# Processa la lista di documenti\n",
        "preprocessed_docs = processor.process(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnMZhmSqmzjU",
        "outputId": "4c9ddc7f-f4c3-4877-946a-8390f3ef51ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Document: {'content': 'Collaborerai anche con i data scientist, i data engineer, gli specialisti\\ndi Internet of Things (IoT), gli amministratori di infrastruttura e gli altri\\nsviluppatori di software per:\\nCome ingegnere di Azure AI, hai esperienza nello sviluppo di soluzioni\\nche utilizzano linguaggi come:\\nSai come usare le API REST e gli SDK per costruire soluzioni di AI\\nsicure che utilizzano l’elaborazione delle immagini, l’elaborazione dei\\nvideo, l’elaborazione del linguaggio naturale, il knowledge mining e la\\ngenerazione di AI su AzureLAB\\nIntroduzione ad Azure Video Indexer: Imparerai a creare un\\naccount di Azure Video Indexer e a navigare nell’interfaccia\\nweb del servizio.\\nCaricamento di un Video: Caricherai un video di esempio che\\nvuoi analizzare con Azure Video Indexer. Il video può essere\\nun file locale o un URL.\\nVisualizzazione dei Risultati dell’Analisi: Una volta caricato il\\nvideo, potrai visualizzare i risultati dell’analisi forniti da Azure\\nVideo Indexer. Potrai esplorare le diverse sezioni, come la\\ntrascrizione, i sentimenti, i volti, i marchi, le parole chiave e le\\nscene.\\nRicerca e Filtraggio dei Risultati: Imparerai a utilizzare le\\nfunzionalità di ricerca e filtraggio di Azure Video Indexer per\\ntrovare informazioni specifiche nel tuo video. Potrai cercare\\nper parola, persona, marchio, sentimento o scena.\\nModifica e Personalizzazione dei Risultati: Scoprirai come\\nmodificare e personalizzare i risultati dell’analisi, come\\ncorreggere la trascrizione, aggiungere o rimuovere volti,\\nmarchi o parole chiave, o cambiare il sentimento.\\nDownload e Condivisione dei Risultati: Infine, imparerai come\\nscaricare e condividere i risultati dell’analisi in diversi formati,\\ncome JSON, VTT, CSV o XML. Potrai anche generare un link o\\nun widget per incorporare il tuo video analizzato in una\\npagina web.Ecco un esempio di laboratorio pratico che copre il tema “Analyze\\nvideo”:\\nLaboratorio Pratico: Analisi di Video con Azure Video Indexer\\nObiettivo: Questo laboratorio ti guiderà attraverso il processo di\\nanalisi di video con Azure Video Indexer, un servizio che ti\\npermette di estrarre informazioni da file video, come trascrizioni,\\nsentimenti, volti, marchi e molto altro.\\nPassaggi del Laboratorio:\\n1.\\n2.\\n3.\\n4.\\n5.\\n6.\\nQuesto laboratorio pratico ti fornirà una solida comprensione di\\ncome utilizzare Azure AI Vision per analizzare i tuoi video e\\nestrarre informazioni utili. Buon divertimento!\\nEcco una descrizione più dettagliata dei contenuti del tuo modulo di corso sull’Intelligenza Artificiale:\\nPianificare e gestire una soluzione di Azure AI: Questo argomento copre la pianificazione e la gestione dei costi per i servizi di\\nintelligenza artificiale di Azure. Si discute di come utilizzare il calcolatore dei prezzi di Azure per pianificare i costi dei servizi di\\nintelligenza artificiale di Azure prima di aggiungere risorse per il servizio per stimare i costi.\\nImplementare soluzioni di supporto alle decisioni: Questo argomento riguarda i Decision Support System (DSS), software di\\nsupporto ai decision maker che forniscono informazioni utili ai processi decisionali in modo rapido e versatile.\\nImplementare soluzioni di computer vision: Questo argomento tratta di come i sistemi di Computer Vision utilizzano i sensori\\nottici di videocamere, fotocamere e altri dispositivi per effettuare riconoscimenti di persone e oggetti.\\n', 'content_type': 'text', 'score': None, 'meta': {'pdf_path': 'Gen-Ai LAB Brochure.pdf', '_split_id': 10}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1e3a2db4a302b86a189f6f70c41c40ba'}>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# a smaller chunked document\n",
        "\n",
        "preprocessed_docs[10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6M7pttrnrQI"
      },
      "source": [
        "# Creazione di uno Store di Documenti in Memoria: 📚💾\n",
        "\n",
        "Stiamo archiviando i nostri documenti in un luogo facilmente accessibile! Nel codice seguente:\n",
        "\n",
        "1. **Inizializzazione di InMemoryDocumentStore:** Con `document_store = InMemoryDocumentStore(use_bm25=True)`, stiamo creando uno store di documenti in memoria. La potenza di memorizzazione è ora nelle nostre mani! 💡🔍\n",
        "\n",
        "   - **Parametro Chiave:**\n",
        "     - `use_bm25`: Abilitiamo BM25, un algoritmo di ranking per la ricerca, per migliorare la precisione delle query. 📊🔗\n",
        "\n",
        "2. **Scrittura dei Documenti nello Store:** Con `document_store.write_documents(preprocessed_docs)`, stiamo scrivendo i documenti pre-elaborati nello store. I nostri documenti sono ora pronti per essere recuperati in qualsiasi momento! 📝💼\n",
        "\n",
        "Questo è il nostro magazzino virtuale pronto a custodire i segreti del nostro progetto! 🚀✨\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40jmeS34m_bM",
        "outputId": "e3cce896-24cc-44ea-92a8-f8e0f809f239"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Updating BM25 representation...: 100%|██████████| 13/13 [00:00<00:00, 1926.03 docs/s]\n"
          ]
        }
      ],
      "source": [
        "from haystack.document_stores import InMemoryDocumentStore\n",
        "\n",
        "document_store = InMemoryDocumentStore(use_bm25=True)\n",
        "document_store.write_documents(preprocessed_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpCA8b2FoZE2"
      },
      "source": [
        "# Configurazione di un Recuperatore BM25 con Haystack: 🔍🚀\n",
        "\n",
        "Stiamo potenziando la nostra ricerca con il retriver BM25! Nel codice seguente:\n",
        "\n",
        "1. **Configurazione di BM25Retriever:** Con `retriever = BM25Retriever(document_store, top_k=2)`, stiamo creando un retriver BM25 che si basa sul nostro store di documenti in memoria. La ricerca ora è pronta a decollare con una top-k di 2 risultati! [BM25 Retriever](https://docs.haystack.deepset.ai/docs/retriever#bm25-recommended) 📈🔗\n",
        "\n",
        "   - **Parametri Chiave:**\n",
        "     - `document_store`: Utilizziamo il nostro store di documenti in memoria come base per la ricerca. 📚💾\n",
        "     - `top_k`: Specifichiamo che vogliamo ottenere i migliori 2 risultati per ciascuna query. 🔝2️⃣\n",
        "\n",
        "Questo retriver è il nostro alleato per trovare i documenti più rilevanti nelle fasi successive! 🌐✨\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UchlKzipUZf"
      },
      "outputs": [],
      "source": [
        "from haystack import Pipeline\n",
        "from haystack.nodes import BM25Retriever\n",
        "retriever = BM25Retriever(document_store, top_k=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4qE7ur59jys"
      },
      "source": [
        "# Definizione di un PromptTemplate per le Domande e Risposte: ❓💬\n",
        "\n",
        "Stiamo dando una struttura alle nostre interazioni domanda-risposta con un `PromptTemplate`! Nel codice seguente:\n",
        "\n",
        "1. **Definizione del Template:** Con `qa_template = PromptTemplate(...)`, stiamo creando un template che guida il processo di domanda e risposta. 📝💬\n",
        "\n",
        "   - **Struttura del Prompt:**\n",
        "     - \"Usando le informazioni contenute nel contesto, rispondi soltanto alla domanda posta senza aggiungere suggestioni di domande e rispondi esclusivamente in italiano.\"\n",
        "     - \"Se la risposta non può essere dedotta dal contesto, rispondi: '\\ Non so\\'.\"\n",
        "     - \"Context: {join(documents)};\"\n",
        "     - \"Question: {query}\"\n",
        "\n",
        "   - **Descrizione Chiara:** Il template fornisce chiare istruzioni su come rispondere alle domande in base al contesto. 🧭💡\n",
        "\n",
        "2. **Variabili del Template:** Utilizziamo variabili come `{join(documents)}` e `{query}` per incorporare dinamicamente le informazioni necessarie nel prompt. Le nostre domande ora sono guidate dal contesto! 🔄🌐\n",
        "\n",
        "Questo template è la chiave per interazioni strutturate e contestualmente informate! 🚀✨\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKStelv4pr_f"
      },
      "outputs": [],
      "source": [
        "qa_template = PromptTemplate(prompt=\n",
        "  \"\"\" Usando esclusivamente le informazioni contenute nel contesto,\n",
        "  rispondi soltanto alla domanda posta senza aggiungere suggestioni di domande possibili e rispondi esclusivamente in italiano.\n",
        "  Se la risposta non può essere dedotta dal contesto, rispondi: \"\\ Non saprei perché non attinente al Contesto.\\\"\n",
        "  Context: {join(documents)};\n",
        "  Question: {query}\n",
        "  \"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93KBaMBP9g23"
      },
      "source": [
        "# Utilizzo di http_client per Richieste HTTP e Inizializzazione di PromptNode: 🌐🤖\n",
        "\n",
        "Stiamo esplorando il mondo delle richieste HTTP e inizializziamo il nostro [PromptNode](https://docs.haystack.deepset.ai/docs/prompt_node)! Nel codice seguente:\n",
        "\n",
        "1. **Inizializzazione di PromptNode:** Con `prompt_node = PromptNode(...)`, stiamo configurando il nostro nodo di prompt per interagire con il modello Zephyr. 🌬️🚀\n",
        "\n",
        "   - **Modello Zephyr:** Specificando `model_name_or_path=\"HuggingFaceH4/zephyr-7b-beta\"`, indichiamo quale modello utilizzare per le risposte alle nostre domande. 🤖💬\n",
        "\n",
        "   - **Chiave API Hugging Face:** Utilizziamo la tua chiave Hugging Face, ottenuta in modo sicuro prima, con `api_key=HF_TOKEN`. La sicurezza è fondamentale! 🔐🌐\n",
        "\n",
        "   - **Template di Prompt Predefinito:** Configuriamo il template di prompt predefinito con `default_prompt_template=qa_template`. Ora il nostro nodo di prompt è pronto a ricevere e rispondere alle domande in modo strutturato! 📄💡\n",
        "\n",
        "   - **Parametri Aggiuntivi del Modello:** Specificando `max_length=500` e `model_kwargs={\"model_max_length\": 5000}`, stiamo impostando limiti sulla lunghezza del testo per garantire un'interazione ottimale con il modello. 📏🚀\n",
        "\n",
        "2. **Utilizzo di http_client:** Con l'uso di `http_client` per le richieste HTTP, stiamo aprendo la porta alla comunicazione bidirezionale con il modello Zephyr. La magia delle richieste online è ora nelle nostre mani! 🌍✨\n",
        "\n",
        "Questo nodo di prompt è la nostra interfaccia diretta con il mondo di Zephyr, pronto a rispondere alle domande in modo intelligente! 💬🌟\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7M8_QmfqGO7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "ae4abda699af4419a133d841f959ef91",
            "9a38f6f1d8a440e9920f493a9e0e291b",
            "e6767995151445fd91cd38329d1eec21",
            "66cb277626064fab8482fe5947f4a445",
            "a1e3b0a0cfce4387899d907218d62ebd",
            "f2b133241c7b49449aa5d9e7c9105e50",
            "9077a46bb6a9429d85e501fecdc86d9c",
            "600de97b1d434fe1bbbc3673110d2c2a",
            "4ee0be1699eb44a1b5e62f4a71c8d2b9",
            "1543e494b8834ab1ba6c019cf6f40cd6",
            "d23c0e67a87f4a3db6800dec90319b99",
            "476f0107351247ff86a62c512d55b32a",
            "03a262822dcc44f7a503b50fbc668fbf",
            "db36fe71ec634f158cd202fb5ecf06ce",
            "183b32404ada4e039935b388fa5ad84b",
            "6867d3b2c3924f9ab6bbe758ed4de698",
            "38d403fa340b49a28d14069f013ef8da",
            "1ddd0b9c31394bd680e49c5fb8b9d43a",
            "231803dd74cd4bc7a6ad5c641dbad341",
            "c3a6cd2d953345e4b49a85b3d35cdf76",
            "1622bba8e78844a2b27b0abd38d2fe1f",
            "51ed4c31b0ce48eab7ecc4119a3793ff",
            "f50ad3b470024398a3765cdf50845f04",
            "d532dbf7d97743f9bd5b4d3f3551950c",
            "b53e39dc2a9b4e19a00a69501eb7e963",
            "4908531cd3d1452ba625eaf5230d9eb5",
            "cef92bdc4b504db09c39e1ad136bd8eb",
            "9b3714add55646a983375c886e7728e4",
            "e9e4f894270c4a869e3fe35fa49775e4",
            "a850d18751f04fd6bc55671b8405f24b",
            "bc76dfbac1424b62b5fdaec6c795f1e6",
            "38e50ff2d32f44d987f4941f811ad3b0",
            "77d3084639fe4c86b9eb744f32073f9a",
            "b6c56c23b8d44a1ea4975d516d8f99fc",
            "49f4cda1110649c79640cda0715fce6b",
            "19f9988be75c4ea08231b019f7036ce9",
            "8679f9c9ed1046a594195c58416fb06f",
            "98f44427c1c84b54afec93863e853309",
            "5baf28b2dda1428bb56b37ab3183281f",
            "e5d348f405304879a2ea003d78e453c4",
            "cd582621cae045a9843b369a0121884e",
            "f4d87fad0bab449a94850b3a443e0d08",
            "0bc9d3abc64d411e846ea22e1c863fb8",
            "56ca79ef0fce436c80bc72e079ea8b5c"
          ]
        },
        "outputId": "5adeeb87-975b-4707-acf3-46b8ae2810ae"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae4abda699af4419a133d841f959ef91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "476f0107351247ff86a62c512d55b32a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f50ad3b470024398a3765cdf50845f04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6c56c23b8d44a1ea4975d516d8f99fc"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Ora puoi utilizzare http_client per le tue richieste HTTP, compresa l'inizializzazione di PromptNode\n",
        "prompt_node = PromptNode(\n",
        "    model_name_or_path=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
        "    api_key=HF_TOKEN,\n",
        "    default_prompt_template=qa_template,\n",
        "    max_length=500,\n",
        "    model_kwargs={\"model_max_length\": 5000}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gx3NRV_-tcS"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzY2gQrd-teN"
      },
      "source": [
        "# Configurazione di una Pipeline con Haystack: 🚀🔗\n",
        "\n",
        "Stiamo creando una sequenza di passaggi per massimizzare l'efficacia del nostro flusso di lavoro! Nel codice seguente:\n",
        "\n",
        "1. **Creazione di una Pipeline RAG:** Con `rag_pipeline = Pipeline()`, stiamo iniziando la costruzione della nostra pipeline per il Recurrent Retrieval Augmented Generation (RAG). 🔄🚀\n",
        "\n",
        "2. **Aggiunta di un Nodo Retriever:** Utilizzando `rag_pipeline.add_node(...)`, stiamo incorporando il nostro retriver BM25. Il nodo \"retriever\" riceverà input dalla \"Query\". La ricerca è ufficialmente in corso! 🔎🔗\n",
        "\n",
        "   - **Nodo Retriever:** Configuriamo il nostro retriver BM25 precedentemente creato. È il nostro esperto di ricerca pronto a fornire i documenti più rilevanti! 📚💼\n",
        "\n",
        "3. **Aggiunta di un Nodo di Prompt:** Con `rag_pipeline.add_node(...)`, stiamo inserendo il nostro nodo di prompt. Il nodo \"prompt_node\" riceverà input dal nodo \"retriever\". La risposta è ora alla portata delle nostre domande! 💬🌐\n",
        "\n",
        "   - **Nodo di Prompt:** Configuriamo il nodo di prompt per interagire con il modello Zephyr. L'interazione tra il retriver e Zephyr è pronta a scatenarsi! 🌬️💡\n",
        "\n",
        "Questa Pipeline è la nostra mappa per navigare tra la ricerca e la generazione intelligente di risposte! 🗺️✨\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzD5jw84oTVr"
      },
      "outputs": [],
      "source": [
        "rag_pipeline = Pipeline()\n",
        "rag_pipeline.add_node(component=retriever, name=\"retriever\", inputs=[\"Query\"])\n",
        "rag_pipeline.add_node(component=prompt_node, name=\"prompt_node\", inputs=[\"retriever\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p15vFZY2-81u"
      },
      "source": [
        "# Utilizzo di pprint per la Stampa Dettagliata delle Risposte: 📄👀\n",
        "\n",
        "Stiamo migliorando la presentazione delle nostre risposte con `pprint` e una funzione dedicata! Nel codice seguente:\n",
        "\n",
        "1. **Import di pprint:** Con `from pprint import pprint`, introduciamo la potenza di pprint per una stampa dettagliata dei risultati. Ora le nostre risposte saranno presentate in modo chiaro e ordinato! 📑👀\n",
        "\n",
        "2. **Definizione di una Funzione di Stampa Risposta:** Con `print_answer = lambda out: pprint(out[\"results\"][0].strip())`, stiamo creando una funzione lambda per stampare in modo dettagliato la risposta principale dal risultato. La nostra presentazione delle risposte è ora più elegante! 🌟💬\n",
        "\n",
        "   - **Parametro di Input:** La funzione `print_answer` richiede un parametro `out` che dovrebbe essere una struttura dati contenente i risultati della nostra pipeline.\n",
        "\n",
        "3. **Stampa Elegante della Risposta:** Con la funzione `print_answer`, possiamo ora ottenere una stampa elegante delle risposte, grazie alla bellezza di `pprint`! 🖨️🌈\n",
        "\n",
        "Questo è il tocco finale per rendere le nostre risposte non solo informative, ma anche visivamente accattivanti! ✨👁️\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHzz1UQlt1M5"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "print_answer = lambda out: pprint(out[\"results\"][0].strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VXJ2W7ju9c9"
      },
      "source": [
        "## Let's try our RAG Pipeline 🎸\n",
        "Finalmente esecuzione della Pipeline RAG con una Query e Stampa della Risposta: 🔍🚀\n",
        "\n",
        "Stiamo mettendo alla prova la nostra pipeline RAG con una domanda e ammirando la risposta! Nel codice seguente:\n",
        "\n",
        "1. **Esecuzione della Pipeline RAG:** Con `rag_pipeline.run(query=\"Quale é la caratteristica del Master?\")`, stiamo invocando la nostra pipeline RAG con una domanda specifica. Il processo di ricerca e generazione è ufficialmente in corso! 🔎🌐\n",
        "\n",
        "   - **Query di Esempio:** \"Quale è la caratteristica del Master?\"\n",
        "\n",
        "2. **Stampa della Risposta:** Utilizzando la funzione `print_answer`, stiamo ottenendo una stampa dettagliata della risposta principale. La nostra risposta è pronta a stupire! 📄👀\n",
        "\n",
        "   - **Notazione Lambda:** Abbiamo definito in precedenza una funzione lambda `print_answer` per presentare in modo dettagliato i risultati.\n",
        "\n",
        "Che la magia della ricerca e generazione delle risposte inizi! 🌟💬\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ua-bETg0qknO",
        "outputId": "5eea72ee-0327-45b2-e503-c353530174b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Answer: La caratteristica del Master è il suo approccio didattico innovativo '\n",
            " \"e pratico, che mette al centro l'apprendimento attraverso laboratori di \"\n",
            " \"gruppo, interazione continua con il mondo reale delle imprese e l'utilizzo \"\n",
            " 'della GenAI come strumento di studio e lavoro. Il Master mira a colmare il '\n",
            " \"divario esistente nell'adozione della GenAI tra le grandi imprese e le PMI, \"\n",
            " 'offrendo opportunità concrete di lavoro e sviluppo professionale.')\n"
          ]
        }
      ],
      "source": [
        "print_answer(rag_pipeline.run(query=\"Quale é la caratteristica del Master?\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TK09Si5Vuv81",
        "outputId": "fd3968c8-a9c0-4978-a315-df2839a2f60c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Answer: Sì, i progetti pratici sono molto validi per una formazione '\n",
            " 'professionale perché permettono di applicare immediatamente le competenze '\n",
            " 'acquisite in situazioni reali. Questo approccio favorisce una migliore '\n",
            " 'comprensione e memorizzazione dei concetti e delle tecniche apprese, oltre a '\n",
            " 'fornire una concreta esperienza lavorativa.')\n"
          ]
        }
      ],
      "source": [
        "print_answer(rag_pipeline.run(query=\"Pensi che i progetti pratici siano validi per una formazione professionale?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_k7sZZtIyT3",
        "outputId": "e6042253-2c18-48f2-dc0d-2dfc45f55c18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(\"Answer: Il settimo ed ultimo modulo del corso, intitolato 'Natural Language \"\n",
            " \"Processing with Transformers', tratterà i chatbot. In particolare, si \"\n",
            " \"imparerà come utilizzare l'API ChatGPT per costruire chatbot e altre \"\n",
            " 'applicazioni di conversazione.')\n"
          ]
        }
      ],
      "source": [
        "print_answer(rag_pipeline.run(query=\"In che modulo tratteremo i chatbots?\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_answer(rag_pipeline.run(query=\"descrivi i contenuti di tutti i laboratori pratici di ciascun modulo in una tabella.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Miv0XFOwv6Uc",
        "outputId": "d4391fcb-2f47-4551-cfe1-84909e67f69e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('| Modulo | Laboratori Pratici |\\n'\n",
            " '  | --- | --- |\\n'\n",
            " \"  | Introduzione all'IA | - Laboratorio di programmazione di base <br> - \"\n",
            " 'Introduzione alla libreria TensorFlow <br> - Esercitazione di base sulla '\n",
            " 'rete neurale <br> - Laboratorio di elaborazione del linguaggio naturale |\\n'\n",
            " '  | Apprendimento Automatico | - Laboratorio di regressione lineare <br> - '\n",
            " 'Laboratorio di alberi decisionali <br> - Laboratorio di reti neurali '\n",
            " 'artificiali <br> - Laboratorio di apprendimento profondo |\\n'\n",
            " '  | Intelligenza Artificiale Generativa | - Laboratorio di generazione di '\n",
            " 'immagini <br> - Laboratorio di generazione di testo <br> - Laboratorio di '\n",
            " 'generazione di musica <br> - Laboratorio di applicazione della GenAI in vari '\n",
            " 'settori |\\n'\n",
            " '  | Applicazione della GenAI in Azienda | - Laboratorio di implementazione '\n",
            " 'della GenAI in situazioni aziendali reali <br> - Laboratorio di sviluppo '\n",
            " 'professionale <br> - Laboratorio di opportunità concrete di lavoro <br> - '\n",
            " 'Laboratorio di studio sul campo |')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7dzb2qN0vEi"
      },
      "source": [
        "## Prepariamo una serie di domande!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afhwhAIivK1P"
      },
      "outputs": [],
      "source": [
        "questions=\"\"\"I moduli sono aggiornati con le ultime tendenze della AI?\n",
        "Conosci altri Corsi che sono piú validi?\n",
        "Il professore ha un curriculum valido?\n",
        "Per chiarire i miei dubbi chi posso contattare?\n",
        "Le lezioni sono in modalitá sincrona?\n",
        "E´previsto uno stage?\n",
        "Durante il Master è prevista la preparazione per il conseguimento di certificati?\"\"\".split(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0dvsMKhvGm2",
        "outputId": "b3daab2d-afb8-450a-8a01-b1eecdede8c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "I moduli sono aggiornati con le ultime tendenze della AI?\n",
            "Answer: Sì, il corso si adatta continuamente all’evoluzione del campo dell’IA, garantendo che i nostri studenti siano sempre al passo con le ultime tendenze e tecnologie.\n",
            "\n",
            "Conosci altri Corsi che sono piú validi?\n",
            "Non saprei perché non attinente al Contesto.\n",
            "\n",
            "Il professore ha un curriculum valido?\n",
            "Answer: Sì, il professore ha un curriculum valido. Ha un Degree Quadriennale in Data Science, un Master Degree in Data Science, due specializzazioni in Machine Learning Scientist e Deep Learning, e una specializzazione in Generative AI with LLMs. Inoltre, ha un profilo LinkedIn e GitHub e partecipa a competizioni su Kaggle.\n",
            "\n",
            "Per chiarire i miei dubbi chi posso contattare?\n",
            "Answer: Puoi contattare il referente del Master attraverso il numero di telefono 06 77207803 o l'indirizzo email formazione@confartigianatopomezia.it forniti nel testo.\n",
            "\n",
            "Le lezioni sono in modalitá sincrona?\n",
            "Answer: Si, le lezioni sono frequentabili soltanto in modalitá live streaming, con interazione real time con il docente.\n",
            "\n",
            "E´previsto uno stage?\n",
            "Answer: Non è previsto uno stage.\n",
            "\n",
            "Durante il Master è prevista la preparazione per il conseguimento di certificati?\n",
            "Answer: Sì, il Master prevede la preparazione per il conseguimento di certificazioni ufficiali riconosciute nel mondo del lavoro e del business, come quelle di Microsoft, LinkedIn e Coursera.\n"
          ]
        }
      ],
      "source": [
        "for q in questions:\n",
        "  print(\"\\n\"+q)\n",
        "  print(rag_pipeline.run(query=q)[\"results\"][0].strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvK5Abk7Imdj"
      },
      "source": [
        "### Ora prova tu stesso a fare delle domande al nostro Assistente AI...."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJXzgXkhIRme"
      },
      "outputs": [],
      "source": [
        "rag_pipeline.run(query=\"**************************\")[\"results\"][0].strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vc1mfZvyIRoJ"
      },
      "outputs": [],
      "source": [
        "rag_pipeline.run(query=\"**************************\")[\"results\"][0].strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMhWOifDIRsl"
      },
      "outputs": [],
      "source": [
        "rag_pipeline.run(query=\"**************************\")[\"results\"][0].strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKlrNuWdIRuf"
      },
      "outputs": [],
      "source": [
        "rag_pipeline.run(query=\"**************************\")[\"results\"][0].strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgJQgh2aIRy3"
      },
      "outputs": [],
      "source": [
        "rag_pipeline.run(query=\"**************************\")[\"results\"][0].strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSEQ_bYSI_rc"
      },
      "outputs": [],
      "source": [
        "rag_pipeline.run(query=\"**************************\")[\"results\"][0].strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCUEnl2mI_tE"
      },
      "outputs": [],
      "source": [
        "rag_pipeline.run(query=\"**************************\")[\"results\"][0].strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOWc3MB2I_xd"
      },
      "outputs": [],
      "source": [
        "rag_pipeline.run(query=\"**************************\")[\"results\"][0].strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8uF0pBNI_-a"
      },
      "outputs": [],
      "source": [
        "rag_pipeline.run(query=\"**************************\")[\"results\"][0].strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swnlpduYLSVu"
      },
      "source": [
        "# Modello [Mixtral-8x7B](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1): Un Aiutante Utile, ma Perfettibile! 🌐🤖\n",
        "\n",
        "Il nostro chatbot, alimentato dal modello Mixtral-8x7B, è pronto a offrire assistenza, ma è importante tenere presente che nessun modello è perfetto. Il percorso verso l'eccellenza continua e il nostro Mixtral-8x7B è pronto a crescere! 💡🪁\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ae4abda699af4419a133d841f959ef91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a38f6f1d8a440e9920f493a9e0e291b",
              "IPY_MODEL_e6767995151445fd91cd38329d1eec21",
              "IPY_MODEL_66cb277626064fab8482fe5947f4a445"
            ],
            "layout": "IPY_MODEL_a1e3b0a0cfce4387899d907218d62ebd"
          }
        },
        "9a38f6f1d8a440e9920f493a9e0e291b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2b133241c7b49449aa5d9e7c9105e50",
            "placeholder": "​",
            "style": "IPY_MODEL_9077a46bb6a9429d85e501fecdc86d9c",
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "e6767995151445fd91cd38329d1eec21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_600de97b1d434fe1bbbc3673110d2c2a",
            "max": 1460,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ee0be1699eb44a1b5e62f4a71c8d2b9",
            "value": 1460
          }
        },
        "66cb277626064fab8482fe5947f4a445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1543e494b8834ab1ba6c019cf6f40cd6",
            "placeholder": "​",
            "style": "IPY_MODEL_d23c0e67a87f4a3db6800dec90319b99",
            "value": " 1.46k/1.46k [00:00&lt;00:00, 71.3kB/s]"
          }
        },
        "a1e3b0a0cfce4387899d907218d62ebd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2b133241c7b49449aa5d9e7c9105e50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9077a46bb6a9429d85e501fecdc86d9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "600de97b1d434fe1bbbc3673110d2c2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ee0be1699eb44a1b5e62f4a71c8d2b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1543e494b8834ab1ba6c019cf6f40cd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d23c0e67a87f4a3db6800dec90319b99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "476f0107351247ff86a62c512d55b32a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03a262822dcc44f7a503b50fbc668fbf",
              "IPY_MODEL_db36fe71ec634f158cd202fb5ecf06ce",
              "IPY_MODEL_183b32404ada4e039935b388fa5ad84b"
            ],
            "layout": "IPY_MODEL_6867d3b2c3924f9ab6bbe758ed4de698"
          }
        },
        "03a262822dcc44f7a503b50fbc668fbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38d403fa340b49a28d14069f013ef8da",
            "placeholder": "​",
            "style": "IPY_MODEL_1ddd0b9c31394bd680e49c5fb8b9d43a",
            "value": "Downloading tokenizer.model: 100%"
          }
        },
        "db36fe71ec634f158cd202fb5ecf06ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_231803dd74cd4bc7a6ad5c641dbad341",
            "max": 493443,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3a6cd2d953345e4b49a85b3d35cdf76",
            "value": 493443
          }
        },
        "183b32404ada4e039935b388fa5ad84b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1622bba8e78844a2b27b0abd38d2fe1f",
            "placeholder": "​",
            "style": "IPY_MODEL_51ed4c31b0ce48eab7ecc4119a3793ff",
            "value": " 493k/493k [00:00&lt;00:00, 5.71MB/s]"
          }
        },
        "6867d3b2c3924f9ab6bbe758ed4de698": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38d403fa340b49a28d14069f013ef8da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ddd0b9c31394bd680e49c5fb8b9d43a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "231803dd74cd4bc7a6ad5c641dbad341": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3a6cd2d953345e4b49a85b3d35cdf76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1622bba8e78844a2b27b0abd38d2fe1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51ed4c31b0ce48eab7ecc4119a3793ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f50ad3b470024398a3765cdf50845f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d532dbf7d97743f9bd5b4d3f3551950c",
              "IPY_MODEL_b53e39dc2a9b4e19a00a69501eb7e963",
              "IPY_MODEL_4908531cd3d1452ba625eaf5230d9eb5"
            ],
            "layout": "IPY_MODEL_cef92bdc4b504db09c39e1ad136bd8eb"
          }
        },
        "d532dbf7d97743f9bd5b4d3f3551950c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b3714add55646a983375c886e7728e4",
            "placeholder": "​",
            "style": "IPY_MODEL_e9e4f894270c4a869e3fe35fa49775e4",
            "value": "Downloading tokenizer.json: 100%"
          }
        },
        "b53e39dc2a9b4e19a00a69501eb7e963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a850d18751f04fd6bc55671b8405f24b",
            "max": 1795303,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc76dfbac1424b62b5fdaec6c795f1e6",
            "value": 1795303
          }
        },
        "4908531cd3d1452ba625eaf5230d9eb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38e50ff2d32f44d987f4941f811ad3b0",
            "placeholder": "​",
            "style": "IPY_MODEL_77d3084639fe4c86b9eb744f32073f9a",
            "value": " 1.80M/1.80M [00:00&lt;00:00, 8.87MB/s]"
          }
        },
        "cef92bdc4b504db09c39e1ad136bd8eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b3714add55646a983375c886e7728e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9e4f894270c4a869e3fe35fa49775e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a850d18751f04fd6bc55671b8405f24b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc76dfbac1424b62b5fdaec6c795f1e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38e50ff2d32f44d987f4941f811ad3b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77d3084639fe4c86b9eb744f32073f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6c56c23b8d44a1ea4975d516d8f99fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49f4cda1110649c79640cda0715fce6b",
              "IPY_MODEL_19f9988be75c4ea08231b019f7036ce9",
              "IPY_MODEL_8679f9c9ed1046a594195c58416fb06f"
            ],
            "layout": "IPY_MODEL_98f44427c1c84b54afec93863e853309"
          }
        },
        "49f4cda1110649c79640cda0715fce6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5baf28b2dda1428bb56b37ab3183281f",
            "placeholder": "​",
            "style": "IPY_MODEL_e5d348f405304879a2ea003d78e453c4",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "19f9988be75c4ea08231b019f7036ce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd582621cae045a9843b369a0121884e",
            "max": 72,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4d87fad0bab449a94850b3a443e0d08",
            "value": 72
          }
        },
        "8679f9c9ed1046a594195c58416fb06f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bc9d3abc64d411e846ea22e1c863fb8",
            "placeholder": "​",
            "style": "IPY_MODEL_56ca79ef0fce436c80bc72e079ea8b5c",
            "value": " 72.0/72.0 [00:00&lt;00:00, 5.12kB/s]"
          }
        },
        "98f44427c1c84b54afec93863e853309": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5baf28b2dda1428bb56b37ab3183281f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5d348f405304879a2ea003d78e453c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd582621cae045a9843b369a0121884e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4d87fad0bab449a94850b3a443e0d08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0bc9d3abc64d411e846ea22e1c863fb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56ca79ef0fce436c80bc72e079ea8b5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}