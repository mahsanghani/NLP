{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82a4d300-af18-4ac9-a772-9a781dc1c678",
      "metadata": {
        "id": "82a4d300-af18-4ac9-a772-9a781dc1c678"
      },
      "outputs": [],
      "source": [
        "!pip install unzip\n",
        "!pip install pandas\n",
        "!pip install tqdm\n",
        "!pip install python-dotenv\n",
        "!pip install neo4j\n",
        "!pip install tenacity\n",
        "!pip install langchain\n",
        "!pip install langchain-google-genai\n",
        "!pip install langchain-ollama\n",
        "!pip install langchain-community\n",
        "!pip install langchain-experimental"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94568ef2-d337-47d9-848e-9ba76f290b11",
      "metadata": {
        "id": "94568ef2-d337-47d9-848e-9ba76f290b11"
      },
      "outputs": [],
      "source": [
        "# !pip install -q kaggle\n",
        "# !pip install google.colab\n",
        "# from google.colab import files\n",
        "\n",
        "# files.upload()\n",
        "\n",
        "# !mkdir ~/.kaggle\n",
        "# !cp kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json\n",
        "# !kaggle datasets list\n",
        "\n",
        "# !kaggle datasets download -d jrobischon/wikipedia-movie-plots\n",
        "# !unzip wikipedia-movie-plots.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd0eba7f-f3de-48c1-809b-ee3db9fadb10",
      "metadata": {
        "id": "cd0eba7f-f3de-48c1-809b-ee3db9fadb10"
      },
      "outputs": [],
      "source": [
        "# !kaggle datasets download -d jrobischon/wikipedia-movie-plots\n",
        "!unzip wikipedia-movie-plots.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab81dcc3-7cea-4e82-bca6-e09cfc647624",
      "metadata": {
        "id": "ab81dcc3-7cea-4e82-bca6-e09cfc647624"
      },
      "outputs": [],
      "source": [
        "# Type hints\n",
        "from typing import Any, Dict, List, Tuple\n",
        "\n",
        "# Standard library\n",
        "import ast\n",
        "import logging\n",
        "import re\n",
        "import warnings\n",
        "\n",
        "# Third-party packages - Data manipulation\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "# from .autonotebook import tqdm as notebook_tqdm\n",
        "\n",
        "# Third-party packages - Environment & Database\n",
        "from dotenv import load_dotenv\n",
        "from neo4j import GraphDatabase\n",
        "\n",
        "# Third-party packages - Error handling & Retry logic\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "\n",
        "# Langchain - Core\n",
        "from langchain.chains import GraphCypherQAChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# Langchain - Models & Connectors\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAI\n",
        "from langchain_ollama.llms import OllamaLLM\n",
        "\n",
        "# Langchain - Graph & Experimental\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da772dfe-d5d0-47e2-be83-85da81034d8c",
      "metadata": {
        "id": "da772dfe-d5d0-47e2-be83-85da81034d8c"
      },
      "outputs": [],
      "source": [
        "movies = pd.read_csv('wiki_movie_plots_deduped.csv') # adjust the path if you manually downloaded the dataset\n",
        "movies.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfaa4fa4-7cae-4a32-a248-cf6389bee33a",
      "metadata": {
        "id": "dfaa4fa4-7cae-4a32-a248-cf6389bee33a"
      },
      "outputs": [],
      "source": [
        "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Clean and preprocess DataFrame.\n",
        "\n",
        "    Args:\n",
        "        data: Input DataFrame\n",
        "\n",
        "    Returns:\n",
        "        Cleaned DataFrame\n",
        "    \"\"\"\n",
        "    df.drop([\"Wiki Page\"], axis=1, inplace=True)\n",
        "\n",
        "    # Drop duplicates\n",
        "    df = df.drop_duplicates(subset='Title', keep='first')\n",
        "\n",
        "    # Get object columns\n",
        "    col_obj = df.select_dtypes(include=[\"object\"]).columns\n",
        "\n",
        "    # Clean string columns\n",
        "    for col in col_obj:\n",
        "        # Strip whitespace\n",
        "        df[col] = df[col].str.strip()\n",
        "\n",
        "        # Replace unknown/empty values\n",
        "        df[col] = df[col].apply(\n",
        "            lambda x: None if pd.isna(x) or x.lower() in [\"\", \"unknown\"]\n",
        "            else x.capitalize()\n",
        "        )\n",
        "\n",
        "    # Drop rows with any null values\n",
        "    df = df.dropna(how=\"any\", axis=0)\n",
        "\n",
        "    return df\n",
        "\n",
        "movies = clean_data(movies).head(1000)\n",
        "movies.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15c9446e-38c4-474f-877a-562b2069f737",
      "metadata": {
        "id": "15c9446e-38c4-474f-877a-562b2069f737"
      },
      "outputs": [],
      "source": [
        "class Neo4jConnection:\n",
        "    def __init__(self, uri, user, password):\n",
        "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
        "\n",
        "    def close(self):\n",
        "        self.driver.close()\n",
        "        print(\"Connection closed\")\n",
        "\n",
        "    def reset_database(self):\n",
        "        with self.driver.session() as session:\n",
        "            session.run(\"MATCH (n) DETACH DELETE n\")\n",
        "            print(\"Database resetted successfully!\")\n",
        "\n",
        "    def execute_query(self, query, parameters=None):\n",
        "        with self.driver.session() as session:\n",
        "            result = session.run(query, parameters or {})\n",
        "            return [record for record in result]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89643358-5e50-49d1-a26f-afb7dece0616",
      "metadata": {
        "id": "89643358-5e50-49d1-a26f-afb7dece0616"
      },
      "outputs": [],
      "source": [
        "uri = \"bolt://localhost:7687\"\n",
        "user = \"neo4j\"\n",
        "password = \"ilovemovies\"\n",
        "conn = Neo4jConnection(uri, user, password)\n",
        "conn.reset_database()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0344f53-4222-4a02-9708-b87c13959def",
      "metadata": {
        "id": "e0344f53-4222-4a02-9708-b87c13959def"
      },
      "outputs": [],
      "source": [
        "def parse_number(value: Any, target_type: type) -> Optional[float]:\n",
        "    \"\"\"Parse string to number with proper error handling.\"\"\"\n",
        "    if pd.isna(value):\n",
        "        return None\n",
        "    try:\n",
        "        cleaned = str(value).strip().replace(',', '')\n",
        "        return target_type(cleaned)\n",
        "    except (ValueError, TypeError):\n",
        "        return None\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    \"\"\"Clean and normalize text fields.\"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    return str(text).strip().title()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93ed18eb-5c4a-44d2-ad3f-47f3f57379de",
      "metadata": {
        "id": "93ed18eb-5c4a-44d2-ad3f-47f3f57379de"
      },
      "outputs": [],
      "source": [
        "def load_movies_to_neo4j(movies_df: pd.DataFrame, connection: GraphDatabase) -> None:\n",
        "    \"\"\"Load movie data into Neo4j with progress tracking and error handling.\"\"\"\n",
        "\n",
        "    logger = logging.getLogger(__name__)\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "    # Query templates\n",
        "    MOVIE_QUERY = \"\"\"\n",
        "        MERGE (movie:Movie {title: $title})\n",
        "        SET movie.year = $year,\n",
        "            movie.origin = $origin,\n",
        "            movie.genre = $genre,\n",
        "            movie.plot = $plot\n",
        "    \"\"\"\n",
        "\n",
        "    DIRECTOR_QUERY = \"\"\"\n",
        "        MATCH (movie:Movie {title: $title})\n",
        "        MERGE (director:Director {name: $name})\n",
        "        MERGE (director)-[:DIRECTED]->(movie)\n",
        "    \"\"\"\n",
        "\n",
        "    ACTOR_QUERY = \"\"\"\n",
        "        MATCH (movie:Movie {title: $title})\n",
        "        MERGE (actor:Actor {name: $name})\n",
        "        MERGE (actor)-[:ACTED_IN]->(movie)\n",
        "    \"\"\"\n",
        "\n",
        "    # Process each movie\n",
        "    for _, row in tqdm(movies_df.iterrows(), total=len(movies_df), desc=\"Loading movies\"):\n",
        "        try:\n",
        "            # Prepare movie parameters\n",
        "            movie_params = {\n",
        "                \"title\": clean_text(row[\"Title\"]),\n",
        "                \"year\": parse_number(row[\"Release Year\"], int),\n",
        "                \"origin\": clean_text(row[\"Origin/Ethnicity\"]),\n",
        "                \"genre\": clean_text(row[\"Genre\"]),\n",
        "                \"plot\": str(row[\"Plot\"]).strip()\n",
        "            }\n",
        "\n",
        "            # Create movie node\n",
        "            connection.execute_query(MOVIE_QUERY, parameters=movie_params)\n",
        "\n",
        "            # Process directors\n",
        "            for director in str(row[\"Director\"]).split(\" and \"):\n",
        "                director_params = {\n",
        "                    \"name\": clean_text(director),\n",
        "                    \"title\": movie_params[\"title\"]\n",
        "                }\n",
        "                connection.execute_query(DIRECTOR_QUERY, parameters=director_params)\n",
        "\n",
        "            # Process cast\n",
        "            if pd.notna(row[\"Cast\"]):\n",
        "                for actor in row[\"Cast\"].split(\",\"):\n",
        "                    actor_params = {\n",
        "                        \"name\": clean_text(actor),\n",
        "                        \"title\": movie_params[\"title\"]\n",
        "                    }\n",
        "                    connection.execute_query(ACTOR_QUERY, parameters=actor_params)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error loading {row['Title']}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    logger.info(\"Finished loading movies to Neo4j\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75049879-a501-4839-80eb-fd2d4e6612cc",
      "metadata": {
        "id": "75049879-a501-4839-80eb-fd2d4e6612cc"
      },
      "outputs": [],
      "source": [
        "load_movies_to_neo4j(movies, conn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93668a44-9891-4afd-b270-933a1bd0ee63",
      "metadata": {
        "id": "93668a44-9891-4afd-b270-933a1bd0ee63"
      },
      "outputs": [],
      "source": [
        "query = \"\"\"\n",
        "MATCH (m:Movie)-[:ACTED_IN]-(a:Actor)\n",
        "RETURN m.title, a.name\n",
        "LIMIT 10;\n",
        "\"\"\"\n",
        "results = conn.execute_query(query)\n",
        "for record in results:\n",
        "    print(record)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08258fa1-5b56-4de0-a3c5-9a51a38c6b27",
      "metadata": {
        "id": "08258fa1-5b56-4de0-a3c5-9a51a38c6b27"
      },
      "outputs": [],
      "source": [
        "# llm = GoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=api_key) # if you are using Google API\n",
        "llm = OllamaLLM(model=\"qwen2.5-coder:latest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d101e723-1361-41cb-bd44-06cb4c36b367",
      "metadata": {
        "id": "d101e723-1361-41cb-bd44-06cb4c36b367"
      },
      "outputs": [],
      "source": [
        "node_structure = \"\\n\".join([\n",
        "    f\"{col}: {', '.join(map(str, movies[col].unique()[:3]))}...\"\n",
        "    for col in movies.columns\n",
        "])\n",
        "print(node_structure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5fe21a3-1684-43c9-95eb-654aa08b1b96",
      "metadata": {
        "id": "c5fe21a3-1684-43c9-95eb-654aa08b1b96"
      },
      "outputs": [],
      "source": [
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def validate_node_definition(node_def: Dict) -> bool:\n",
        "    \"\"\"Validate node definition structure\"\"\"\n",
        "    if not isinstance(node_def, dict):\n",
        "        return False\n",
        "    return all(\n",
        "        isinstance(v, dict) and all(isinstance(k, str) for k in v.keys())\n",
        "        for v in node_def.values()\n",
        "    )\n",
        "\n",
        "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
        "def get_node_definitions(chain, structure: str, example: Dict) -> Dict[str, Dict[str, str]]:\n",
        "    \"\"\"Get node definitions with retry logic\"\"\"\n",
        "    try:\n",
        "        # Get response from LLM\n",
        "        response = chain.invoke({\"structure\": structure, \"example\": example})\n",
        "\n",
        "        # Parse response\n",
        "        node_defs = ast.literal_eval(response)\n",
        "\n",
        "        # Validate structure\n",
        "        if not validate_node_definition(node_defs):\n",
        "            raise ValueError(\"Invalid node definition structure\")\n",
        "\n",
        "        return node_defs\n",
        "\n",
        "    except (ValueError, SyntaxError) as e:\n",
        "        logger.error(f\"Error parsing node definitions: {e}\")\n",
        "        raise\n",
        "\n",
        "# Updated node definition template\n",
        "node_example = {\n",
        "    \"NodeLabel1\": {\"property1\": \"row['property1']\", \"property2\": \"row['property2']\"},\n",
        "    \"NodeLabel2\": {\"property1\": \"row['property1']\", \"property2\": \"row['property2']\"},\n",
        "    \"NodeLabel3\": {\"property1\": \"row['property1']\", \"property2\": \"row['property2']\"},\n",
        "}\n",
        "\n",
        "define_nodes_prompt = PromptTemplate(\n",
        "    input_variables=[\"example\", \"structure\"],\n",
        "    template=(\"\"\"\n",
        "        Analyze the dataset structure below and extract the entity labels for nodes and their properties.\\n\n",
        "        The node properties should be based on the dataset columns and their values.\\n\n",
        "        Return the result as a dictionary where the keys are the node labels and the values are the node properties.\\n\\n\n",
        "        Example: {example}\\n\\n\n",
        "\n",
        "        Dataset Structure:\\n{structure}\\n\\n\n",
        "\n",
        "        Make sure to include all the possible node labels and their properties.\\n\n",
        "        If a property can be its own node, include it as a separate node label.\\n\n",
        "        Please do not report triple backticks to identify a code block, just return the list of tuples.\\n\n",
        "        Return only the dictionary containing node labels and properties, and don't include any other text or quotation.\n",
        "\n",
        "        \"\"\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Execute with error handling\n",
        "try:\n",
        "    node_chain = define_nodes_prompt | llm\n",
        "\n",
        "    node_definitions = get_node_definitions(node_chain, structure=node_structure, example=node_example)\n",
        "    logger.info(f\"Node Definitions: {node_definitions}\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Failed to get node definitions: {e}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "996c4aeb-9dc6-4608-a25d-7e236c461eab",
      "metadata": {
        "id": "996c4aeb-9dc6-4608-a25d-7e236c461eab"
      },
      "outputs": [],
      "source": [
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5f3402c-fc61-4f4a-8299-4171977d48e2",
      "metadata": {
        "id": "f5f3402c-fc61-4f4a-8299-4171977d48e2"
      },
      "outputs": [],
      "source": [
        "def validate_node_definition(node_def: Dict) -> bool:\n",
        "    \"\"\"Validate node definition structure\"\"\"\n",
        "    if not isinstance(node_def, dict):\n",
        "        return False\n",
        "    return all(\n",
        "        isinstance(v, dict) and all(isinstance(k, str) for k in v.keys())\n",
        "        for v in node_def.values()\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5095824-57d7-4ee4-8248-5f6691b9e8cd",
      "metadata": {
        "id": "b5095824-57d7-4ee4-8248-5f6691b9e8cd"
      },
      "outputs": [],
      "source": [
        "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
        "def get_node_definitions(chain, structure: str, example: Dict) -> Dict[str, Dict[str, str]]:\n",
        "    \"\"\"Get node definitions with retry logic\"\"\"\n",
        "    try:\n",
        "        # Get response from LLM\n",
        "        response = chain.invoke({\"structure\": structure, \"example\": example})\n",
        "\n",
        "        # Parse response\n",
        "        node_defs = ast.literal_eval(response)\n",
        "\n",
        "        # Validate structure\n",
        "        if not validate_node_definition(node_defs):\n",
        "            raise ValueError(\"Invalid node definition structure\")\n",
        "\n",
        "        return node_defs\n",
        "    except (ValueError, SyntaxError) as e:\n",
        "        logger.error(f\"Error parsing node definitions: {e}\")\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdb7632d-bfaa-4c11-a785-e85a39606a98",
      "metadata": {
        "id": "cdb7632d-bfaa-4c11-a785-e85a39606a98"
      },
      "outputs": [],
      "source": [
        "define_nodes_prompt = PromptTemplate(\n",
        "    input_variables=[\"example\", \"structure\"],\n",
        "    template=(\"\"\"\n",
        "        Analyze the dataset structure below and extract the entity labels for nodes and their properties.\\n\n",
        "        The node properties should be based on the dataset columns and their values.\\n\n",
        "        Return the result as a dictionary where the keys are the node labels and the values are the node properties.\\n\\n\n",
        "        Example: {example}\\n\\n\n",
        "        Dataset Structure:\\n{structure}\\n\\n\n",
        "        Make sure to include all the possible node labels and their properties.\\n\n",
        "        If a property can be its own node, include it as a separate node label.\\n\n",
        "        Please do not report triple backticks to identify a code block, just return the list of tuples.\\n\n",
        "        Return only the dictionary containing node labels and properties, and don't include any other text or quotation.\n",
        "    \"\"\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dd7fc87-bd7d-4714-bae4-3aafb060b184",
      "metadata": {
        "id": "7dd7fc87-bd7d-4714-bae4-3aafb060b184"
      },
      "outputs": [],
      "source": [
        "node_example = {\n",
        "    \"NodeLabel1\": {\"property1\": \"row['property1']\", \"property2\": \"row['property2']\"},\n",
        "    \"NodeLabel2\": {\"property1\": \"row['property1']\", \"property2\": \"row['property2']\"},\n",
        "    \"NodeLabel3\": {\"property1\": \"row['property1']\", \"property2\": \"row['property2']\"},\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cecca46f-7d24-4fe8-98b4-d49e13b109e4",
      "metadata": {
        "id": "cecca46f-7d24-4fe8-98b4-d49e13b109e4"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    node_chain = define_nodes_prompt | llm\n",
        "    node_definitions = get_node_definitions(node_chain, structure=node_structure, example=node_example)\n",
        "    logger.info(f\"Node Definitions: {node_definitions}\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Failed to get node definitions: {e}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c281f29d-5685-46f4-b72d-2faabbb6521b",
      "metadata": {
        "id": "c281f29d-5685-46f4-b72d-2faabbb6521b"
      },
      "outputs": [],
      "source": [
        "class RelationshipIdentifier:\n",
        "    \"\"\"Identifies relationships between nodes in a graph database.\"\"\"\n",
        "\n",
        "    RELATIONSHIP_EXAMPLE = [\n",
        "        (\"NodeLabel1\", \"RelationshipLabel\", \"NodeLabel2\"),\n",
        "        (\"NodeLabel1\", \"RelationshipLabel\", \"NodeLabel3\"),\n",
        "        (\"NodeLabel2\", \"RelationshipLabel\", \"NodeLabel3\"),\n",
        "    ]\n",
        "\n",
        "\n",
        "    PROMPT_TEMPLATE = PromptTemplate(\n",
        "    input_variables=[\"structure\", \"node_definitions\", \"example\"],\n",
        "    template=\"\"\"\n",
        "        Consider the following Dataset Structure:\\n{structure}\\n\\n\n",
        "\n",
        "        Consider the following Node Definitions:\\n{node_definitions}\\n\\n\n",
        "\n",
        "        Based on the dataset structure and node definitions, identify relationships (edges) between nodes.\\n\n",
        "        Return the relationships as a list of triples where each triple contains the start node label, relationship label, and end node label, and each triple is a tuple.\\n\n",
        "        Please return only the list of tuples. Please do not report triple backticks to identify a code block, just return the list of tuples.\\n\\n\n",
        "\n",
        "        Example:\\n{example}\n",
        "        \"\"\"\n",
        ")\n",
        "\n",
        "    def __init__(self, llm: Any, logger: logging.Logger = None):\n",
        "        self.llm = llm\n",
        "        self.logger = logger or logging.getLogger(__name__)\n",
        "        self.chain = self.PROMPT_TEMPLATE | self.llm\n",
        "\n",
        "    def validate_relationships(self, relationships: List[Tuple]) -> bool:\n",
        "        \"\"\"Validate relationship structure.\"\"\"\n",
        "        return all(\n",
        "            isinstance(rel, tuple) and\n",
        "            len(rel) == 3 and\n",
        "            all(isinstance(x, str) for x in rel)\n",
        "            for rel in relationships\n",
        "        )\n",
        "\n",
        "    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
        "    def identify_relationships(self, structure: str, node_definitions: Dict) -> List[Tuple]:\n",
        "        \"\"\"Identify relationships with retry logic.\"\"\"\n",
        "        try:\n",
        "            response = self.chain.invoke({\n",
        "                \"structure\": structure,\n",
        "                \"node_definitions\": str(node_definitions),\n",
        "                \"example\": str(self.RELATIONSHIP_EXAMPLE)\n",
        "            })\n",
        "\n",
        "            relationships = ast.literal_eval(response)\n",
        "\n",
        "            if not self.validate_relationships(relationships):\n",
        "                raise ValueError(\"Invalid relationship structure\")\n",
        "\n",
        "            self.logger.info(f\"Identified {len(relationships)} relationships\")\n",
        "            return relationships\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error identifying relationships: {e}\")\n",
        "            raise\n",
        "\n",
        "    def get_relationship_types(self) -> List[str]:\n",
        "        \"\"\"Extract unique relationship types.\"\"\"\n",
        "        return list(set(rel[1] for rel in self.identify_relationships()))\n",
        "\n",
        "# Usage\n",
        "identifier = RelationshipIdentifier(llm=llm)\n",
        "relationships = identifier.identify_relationships(node_structure, node_definitions)\n",
        "print(\"Relationships:\", relationships)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0718016e-5145-452a-b817-13a7d797069a",
      "metadata": {
        "id": "0718016e-5145-452a-b817-13a7d797069a"
      },
      "outputs": [],
      "source": [
        "RELATIONSHIP_EXAMPLE = [\n",
        "    (\"NodeLabel1\", \"RelationshipLabel\", \"NodeLabel2\"),\n",
        "    (\"NodeLabel1\", \"RelationshipLabel\", \"NodeLabel3\"),\n",
        "    (\"NodeLabel2\", \"RelationshipLabel\", \"NodeLabel3\"),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97233e08-6ce7-4b40-bf92-f8c4c396d56e",
      "metadata": {
        "id": "97233e08-6ce7-4b40-bf92-f8c4c396d56e"
      },
      "outputs": [],
      "source": [
        "PROMPT_TEMPLATE = PromptTemplate(\n",
        "    input_variables=[\"structure\", \"node_definitions\", \"example\"],\n",
        "    template=\"\"\"\n",
        "        Consider the following Dataset Structure:\\n{structure}\\n\\n\n",
        "\n",
        "        Consider the following Node Definitions:\\n{node_definitions}\\n\\n\n",
        "\n",
        "        Based on the dataset structure and node definitions, identify relationships (edges) between nodes.\\n\n",
        "        Return the relationships as a list of triples where each triple contains the start node label, relationship label, and end node label, and each triple is a tuple.\\n\n",
        "        Please return only the list of tuples. Please do not report triple backticks to identify a code block, just return the list of tuples.\\n\\n\n",
        "\n",
        "        Example:\\n{example}\n",
        "        \"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e37bd6b0-a932-48f2-9a24-63c7097d8cd0",
      "metadata": {
        "id": "e37bd6b0-a932-48f2-9a24-63c7097d8cd0"
      },
      "outputs": [],
      "source": [
        "def __init__(self, llm: Any, logger: logging.Logger = None):\n",
        "    self.llm = llm\n",
        "    self.logger = logger or logging.getLogger(__name__)\n",
        "    self.chain = self.PROMPT_TEMPLATE | self.llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "813cbf6e-577e-4630-8ce6-1c13336c1db3",
      "metadata": {
        "id": "813cbf6e-577e-4630-8ce6-1c13336c1db3"
      },
      "outputs": [],
      "source": [
        "def validate_relationships(self, relationships: List[Tuple]) -> bool:\n",
        "    \"\"\"Validate relationship structure.\"\"\"\n",
        "    return all(\n",
        "        isinstance(rel, tuple) and\n",
        "        len(rel) == 3 and\n",
        "        all(isinstance(x, str) for x in rel)\n",
        "        for rel in relationships\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "132d0499-d876-4cc7-960c-9db8bb7fcd4b",
      "metadata": {
        "id": "132d0499-d876-4cc7-960c-9db8bb7fcd4b"
      },
      "outputs": [],
      "source": [
        "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
        "def identify_relationships(self, structure: str, node_definitions: Dict) -> List[Tuple]:\n",
        "    \"\"\"Identify relationships with retry logic.\"\"\"\n",
        "    try:\n",
        "        response = self.chain.invoke({\n",
        "            \"structure\": structure,\n",
        "            \"node_definitions\": str(node_definitions),\n",
        "            \"example\": str(self.RELATIONSHIP_EXAMPLE)\n",
        "        })\n",
        "\n",
        "        relationships = ast.literal_eval(response)\n",
        "\n",
        "        if not self.validate_relationships(relationships):\n",
        "            raise ValueError(\"Invalid relationship structure\")\n",
        "\n",
        "        self.logger.info(f\"Identified {len(relationships)} relationships\")\n",
        "        return relationships\n",
        "    except Exception as e:\n",
        "        self.logger.error(f\"Error identifying relationships: {e}\")\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec7f4160-4b26-4554-a518-3d4940d60ff4",
      "metadata": {
        "id": "ec7f4160-4b26-4554-a518-3d4940d60ff4"
      },
      "outputs": [],
      "source": [
        "def get_relationship_types(self) -> List[str]:\n",
        "    \"\"\"Extract unique relationship types.\"\"\"\n",
        "    return list(set(rel[1] for rel in self.identify_relationships()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf66195d-0b90-4c96-9817-a3538e3c55ec",
      "metadata": {
        "id": "cf66195d-0b90-4c96-9817-a3538e3c55ec"
      },
      "outputs": [],
      "source": [
        "identifier = RelationshipIdentifier(llm=llm)\n",
        "relationships = identifier.identify_relationships(node_structure, node_definitions)\n",
        "print(\"Relationships:\", relationships)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eef9c63a-77b3-4534-9ff3-1c8f30b1b4e7",
      "metadata": {
        "id": "eef9c63a-77b3-4534-9ff3-1c8f30b1b4e7"
      },
      "outputs": [],
      "source": [
        "class CypherQueryBuilder:\n",
        "    \"\"\"Builds Cypher queries for Neo4j graph database.\"\"\"\n",
        "\n",
        "    INPUT_EXAMPLE = \"\"\"\n",
        "    NodeLabel1: value1, value2\n",
        "    NodeLabel2: value1, value2\n",
        "    \"\"\"\n",
        "\n",
        "    EXAMPLE_CYPHER = example_cypher = \"\"\"\n",
        "    CREATE (n1:NodeLabel1 {property1: \"row['property1']\", property2: \"row['property2']\"})\n",
        "    CREATE (n2:NodeLabel2 {property1: \"row['property1']\", property2: \"row['property2']\"})\n",
        "    CREATE (n1)-[:RelationshipLabel]->(n2);\n",
        "    \"\"\"\n",
        "\n",
        "    PROMPT_TEMPLATE = PromptTemplate(\n",
        "    input_variables=[\"structure\", \"node_definitions\", \"relationships\", \"example\"],\n",
        "    template=\"\"\"\n",
        "        Consider the following Node Definitions:\\n{node_definitions}\\n\\n\n",
        "        Consider the following Relationships:\\n{relationships}\\n\\n\n",
        "        Generate Cypher queries to create nodes and relationships using the node definitions and relationships below. Remember to replace the placeholder values with actual data from the dataset.\\n\n",
        "        Include all the properties in the Node Definitions for each node as defined and create relationships.\\n\n",
        "        Return a single string with each query separated by a semicolon.\\n\n",
        "        Don't include any other text or quotation marks in the response.\\n\n",
        "        Please return only the string containing Cypher queries. Please do not report triple backticks to identify a code block.\\n\\n\n",
        "\n",
        "        Example Input:\\n{input}\\n\\n\n",
        "\n",
        "        Example Output Cypher query:\\n{cypher}\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "    def __init__(self, llm: Any, logger: logging.Logger = None):\n",
        "        self.llm = llm\n",
        "        self.logger = logger or logging.getLogger(__name__)\n",
        "        # self.chain = LLMChain(llm=llm, prompt=self.PROMPT_TEMPLATE)\n",
        "        self.chain = self.PROMPT_TEMPLATE | self.llm\n",
        "\n",
        "    def validate_cypher_query(self, query: str) -> bool:\n",
        "        \"\"\"Validate Cypher query syntax using LLM and regex patterns.\"\"\"\n",
        "\n",
        "        VALIDATION_PROMPT = PromptTemplate(\n",
        "            input_variables=[\"query\"],\n",
        "            template=\"\"\"\n",
        "            Validate this Cypher query and return TRUE or FALSE:\n",
        "\n",
        "            Query: {query}\n",
        "\n",
        "            Rules to check:\n",
        "            1. Valid CREATE statements\n",
        "            2. Proper property formatting\n",
        "            3. Valid relationship syntax\n",
        "            4. No missing parentheses\n",
        "            5. Valid property names\n",
        "            6. Valid relationship types\n",
        "\n",
        "            Return only TRUE if query is valid, FALSE if invalid.\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            # Basic pattern validation\n",
        "            basic_valid = all(re.search(pattern, query) for pattern in [\n",
        "                r'CREATE \\(',\n",
        "                r'\\{.*?\\}',\n",
        "                r'\\)-\\[:.*?\\]->'\n",
        "            ])\n",
        "\n",
        "            if not basic_valid:\n",
        "                return False\n",
        "\n",
        "            # LLM validation\n",
        "            validation_chain = VALIDATION_PROMPT | self.llm\n",
        "            result = validation_chain.invoke({\"query\": query})\n",
        "\n",
        "            # Parse result\n",
        "            is_valid = \"TRUE\" in result.upper()\n",
        "\n",
        "            if not is_valid:\n",
        "                self.logger.warning(f\"LLM validation failed for query: {query}\")\n",
        "\n",
        "            return is_valid\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Validation error: {e}\")\n",
        "            return False\n",
        "\n",
        "    def sanitize_query(self, query: str) -> str:\n",
        "        \"\"\"Sanitize and format Cypher query.\"\"\"\n",
        "        return (query\n",
        "                .strip()\n",
        "                .replace('\\n', ' ')\n",
        "                .replace('  ', ' ')\n",
        "                .replace(\"'row[\", \"row['\")\n",
        "                .replace(\"]'\", \"']\"))\n",
        "\n",
        "    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
        "    def build_queries(self, node_definitions: Dict, relationships: List) -> str:\n",
        "        \"\"\"Build Cypher queries with retry logic.\"\"\"\n",
        "        try:\n",
        "            response = self.chain.invoke({\n",
        "                \"node_definitions\": str(node_definitions),\n",
        "                \"relationships\": str(relationships),\n",
        "                \"input\": self.INPUT_EXAMPLE,\n",
        "                \"cypher\": self.EXAMPLE_CYPHER\n",
        "            })\n",
        "\n",
        "            # Get response inside triple backticks\n",
        "            if '```' in response:\n",
        "                response = response.split('```')[1]\n",
        "\n",
        "\n",
        "            # Sanitize response\n",
        "            queries = self.sanitize_query(response)\n",
        "\n",
        "            # Validate queries\n",
        "            if not self.validate_cypher_query(queries):\n",
        "                raise ValueError(\"Invalid Cypher query syntax\")\n",
        "\n",
        "            self.logger.info(\"Successfully generated Cypher queries\")\n",
        "            return queries\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error building Cypher queries: {e}\")\n",
        "            raise\n",
        "\n",
        "    def split_queries(self, queries: str) -> List[str]:\n",
        "        \"\"\"Split combined queries into individual statements.\"\"\"\n",
        "        return [q.strip() for q in queries.split(';') if q.strip()]\n",
        "\n",
        "# Usage\n",
        "builder = CypherQueryBuilder(llm=llm)\n",
        "cypher_queries = builder.build_queries(node_definitions, relationships)\n",
        "print(\"Cypher Queries:\", cypher_queries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8db6fd2-19b0-4c95-877d-4e01ab395f24",
      "metadata": {
        "id": "b8db6fd2-19b0-4c95-877d-4e01ab395f24"
      },
      "outputs": [],
      "source": [
        "PROMPT_TEMPLATE = PromptTemplate(\n",
        "    input_variables=[\"structure\", \"node_definitions\", \"relationships\", \"example\"],\n",
        "    template=\"\"\"\n",
        "        Consider the following Node Definitions:\\n{node_definitions}\\n\\n\n",
        "        Consider the following Relationships:\\n{relationships}\\n\\n\n",
        "        Generate Cypher queries to create nodes and relationships using the node definitions and relationships below. Remember to replace the placeholder values with actual data from the dataset.\\n\n",
        "        Include all the properties in the Node Definitions for each node as defined and create relationships.\\n\n",
        "        Return a single string with each query separated by a semicolon.\\n\n",
        "        Don't include any other text or quotation marks in the response.\\n\n",
        "        Please return only the string containing Cypher queries. Please do not report triple backticks to identify a code block.\\n\\n\n",
        "\n",
        "        Example Input:\\n{input}\\n\\n\n",
        "\n",
        "        Example Output Cypher query:\\n{cypher}\n",
        "    \"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cfdd7a8-11d1-41d6-a4ef-ae54dce50c9f",
      "metadata": {
        "id": "0cfdd7a8-11d1-41d6-a4ef-ae54dce50c9f"
      },
      "outputs": [],
      "source": [
        "def __init__(self, llm: Any, logger: logging.Logger = None):\n",
        "    self.llm = llm\n",
        "    self.logger = logger or logging.getLogger(__name__)\n",
        "    self.chain = self.PROMPT_TEMPLATE | self.llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2317ce7c-7b84-4f1f-9ae1-49a4b1f8ce6a",
      "metadata": {
        "id": "2317ce7c-7b84-4f1f-9ae1-49a4b1f8ce6a"
      },
      "outputs": [],
      "source": [
        "def validate_cypher_query(self, query: str) -> bool:\n",
        "    \"\"\"Validate Cypher query syntax using LLM and regex patterns.\"\"\"\n",
        "\n",
        "    VALIDATION_PROMPT = PromptTemplate(\n",
        "        input_variables=[\"query\"],\n",
        "        template=\"\"\"\n",
        "        Validate this Cypher query and return TRUE or FALSE:\n",
        "\n",
        "        Query: {query}\n",
        "\n",
        "        Rules to check:\n",
        "        1. Valid CREATE statements\n",
        "        2. Proper property formatting\n",
        "        3. Valid relationship syntax\n",
        "        4. No missing parentheses\n",
        "        5. Valid property names\n",
        "        6. Valid relationship types\n",
        "\n",
        "        Return only TRUE if query is valid, FALSE if invalid.\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        # Basic pattern validation\n",
        "        basic_valid = all(re.search(pattern, query) for pattern in [\n",
        "            r'CREATE \\(',\n",
        "            r'\\{.*?\\}',\n",
        "            r'\\)-\\[:.*?\\]->'\n",
        "        ])\n",
        "\n",
        "        if not basic_valid:\n",
        "            return False\n",
        "\n",
        "        # LLM validation\n",
        "        validation_chain = VALIDATION_PROMPT | self.llm\n",
        "        result = validation_chain.invoke({\"query\": query})\n",
        "\n",
        "        # Parse result\n",
        "        is_valid = \"TRUE\" in result.upper()\n",
        "\n",
        "        if not is_valid:\n",
        "            self.logger.warning(f\"LLM validation failed for query: {query}\")\n",
        "\n",
        "        return is_valid\n",
        "\n",
        "    except Exception as e:\n",
        "        self.logger.error(f\"Validation error: {e}\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6db9563e-a15d-4f8d-8a22-80525c784a4e",
      "metadata": {
        "id": "6db9563e-a15d-4f8d-8a22-80525c784a4e"
      },
      "outputs": [],
      "source": [
        "basic_valid = all(re.search(pattern, query) for pattern in [\n",
        "    r'CREATE \\(',\n",
        "    r'\\{.*?\\}',\n",
        "    r'\\)-\\[:.*?\\]->'\n",
        "])\n",
        "if not basic_valid:\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d84c6c09-ff13-4a7d-b7bd-07b140c0e0bc",
      "metadata": {
        "id": "d84c6c09-ff13-4a7d-b7bd-07b140c0e0bc"
      },
      "outputs": [],
      "source": [
        "validation_chain = VALIDATION_PROMPT | self.llm\n",
        "result = validation_chain.invoke({\"query\": query})\n",
        "is_valid = \"TRUE\" in result.upper()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df2225d9-be06-49a2-9512-5c2dd61fdfc1",
      "metadata": {
        "id": "df2225d9-be06-49a2-9512-5c2dd61fdfc1"
      },
      "outputs": [],
      "source": [
        "def sanitize_query(self, query: str) -> str:\n",
        "    \"\"\"Sanitize and format Cypher query.\"\"\"\n",
        "    return (query\n",
        "            .strip()\n",
        "            .replace('\\n', ' ')\n",
        "            .replace('  ', ' ')\n",
        "            .replace(\"'row[\", \"row['\")\n",
        "            .replace(\"]'\", \"']\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e8e07ae-243f-429a-9830-355275d09b19",
      "metadata": {
        "id": "0e8e07ae-243f-429a-9830-355275d09b19"
      },
      "outputs": [],
      "source": [
        "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
        "    def build_queries(self, node_definitions: Dict, relationships: List) -> str:\n",
        "        \"\"\"Build Cypher queries with retry logic.\"\"\"\n",
        "        try:\n",
        "            response = self.chain.invoke({\n",
        "                \"node_definitions\": str(node_definitions),\n",
        "                \"relationships\": str(relationships),\n",
        "                \"input\": self.INPUT_EXAMPLE,\n",
        "                \"cypher\": self.EXAMPLE_CYPHER\n",
        "            })\n",
        "\n",
        "            # Get response inside triple backticks\n",
        "            if '```' in response:\n",
        "                response = response.split('```')[1]\n",
        "\n",
        "\n",
        "            # Sanitize response\n",
        "            queries = self.sanitize_query(response)\n",
        "\n",
        "            # Validate queries\n",
        "            if not self.validate_cypher_query(queries):\n",
        "                raise ValueError(\"Invalid Cypher query syntax\")\n",
        "\n",
        "            self.logger.info(\"Successfully generated Cypher queries\")\n",
        "            return queries\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error building Cypher queries: {e}\")\n",
        "            raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e048044-31d7-47ec-a652-4e21695086d4",
      "metadata": {
        "id": "7e048044-31d7-47ec-a652-4e21695086d4"
      },
      "outputs": [],
      "source": [
        "if '```' in response:\n",
        "    response = response.split('```')[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "031f06d3-6208-4ca8-9542-4c436ae1469f",
      "metadata": {
        "id": "031f06d3-6208-4ca8-9542-4c436ae1469f"
      },
      "outputs": [],
      "source": [
        "def split_queries(self, queries: str) -> List[str]:\n",
        "    \"\"\"Split combined queries into individual statements.\"\"\"\n",
        "    return [q.strip() for q in queries.split(';') if q.strip()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e730227d-6862-4a03-9f8a-3b04857a138a",
      "metadata": {
        "id": "e730227d-6862-4a03-9f8a-3b04857a138a"
      },
      "outputs": [],
      "source": [
        "# CREATE (n1:Movie {title: \"Inception\"}); CREATE (n2:Director {name: \"Nolan\"});\n",
        "\n",
        "# [\"CREATE (n1:Movie {title: 'Inception'})\", \"CREATE (n2:Director {name: 'Nolan'})\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e460264a-b626-49e4-ba63-dd4fca7ecdb8",
      "metadata": {
        "id": "e460264a-b626-49e4-ba63-dd4fca7ecdb8"
      },
      "outputs": [],
      "source": [
        "builder = CypherQueryBuilder(llm=llm)\n",
        "cypher_queries = builder.build_queries(node_definitions, relationships)\n",
        "print(\"Cypher Queries:\", cypher_queries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "710f21f5-7c9f-422c-a889-97d1ee797991",
      "metadata": {
        "id": "710f21f5-7c9f-422c-a889-97d1ee797991"
      },
      "outputs": [],
      "source": [
        "logs = \"\"\n",
        "total_rows = len(df)\n",
        "\n",
        "def sanitize_value(value):\n",
        "    if isinstance(value, str):\n",
        "        return value.replace('\"', '')\n",
        "    return str(value)\n",
        "\n",
        "for index, row in tqdm(df.iterrows(),\n",
        "                      total=total_rows,\n",
        "                      desc=\"Loading data to Neo4j\",\n",
        "                      position=0,\n",
        "                      leave=True):\n",
        "\n",
        "    # Replace placeholders with actual values\n",
        "    cypher_query = cypher_queries\n",
        "    for column in df.columns:\n",
        "        cypher_query = cypher_query.replace(\n",
        "            f\"row['{column}']\",\n",
        "            f'{sanitize_value(row[column])}'\n",
        "        )\n",
        "\n",
        "    try:\n",
        "        # Execute query and update progress\n",
        "        conn.execute_query(cypher_query)\n",
        "    except Exception as e:\n",
        "        logs += f\"Error on row {index+1}: {str(e)}\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4afd3ff1-fb82-4b28-a272-11abbed90076",
      "metadata": {
        "id": "4afd3ff1-fb82-4b28-a272-11abbed90076"
      },
      "outputs": [],
      "source": [
        "def sanitize_value(value):\n",
        "    if isinstance(value, str):\n",
        "        return value.replace('\"', '')\n",
        "    return str(value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ab0f6a5-2e3f-4e18-bc26-824af34d07b5",
      "metadata": {
        "id": "6ab0f6a5-2e3f-4e18-bc26-824af34d07b5"
      },
      "outputs": [],
      "source": [
        "for index, row in tqdm(df.iterrows(),\n",
        "                      total=total_rows,\n",
        "                      desc=\"Loading data to Neo4j\",\n",
        "                      position=0,\n",
        "                      leave=True):\n",
        "\n",
        "    # Replace placeholders with actual values\n",
        "    cypher_query = cypher_queries\n",
        "    for column in df.columns:\n",
        "        cypher_query = cypher_query.replace(\n",
        "            f\"row['{column}']\",\n",
        "            f'{sanitize_value(row[column])}'\n",
        "        )\n",
        "\n",
        "    try:\n",
        "        # Execute query and update progress\n",
        "        conn.execute_query(cypher_query)\n",
        "    except Exception as e:\n",
        "        logs += f\"Error on row {index+1}: {str(e)}\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4061d020-2dda-41f9-b365-81364709e6ee",
      "metadata": {
        "id": "4061d020-2dda-41f9-b365-81364709e6ee"
      },
      "outputs": [],
      "source": [
        "llm_transformer = LLMGraphTransformer(\n",
        "    llm=llm,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1da3e5fe-9132-48e1-b905-c9bc5408e40c",
      "metadata": {
        "id": "1da3e5fe-9132-48e1-b905-c9bc5408e40c"
      },
      "outputs": [],
      "source": [
        "df_sample = df.head(100)  # Reduce sample size for faster processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8add82f-628c-40b3-a239-30731f9cf5e9",
      "metadata": {
        "id": "e8add82f-628c-40b3-a239-30731f9cf5e9"
      },
      "outputs": [],
      "source": [
        "df_sample = movies.head(100)\n",
        "\n",
        "documents = []\n",
        "for _, row in tqdm(df_sample.iterrows(),\n",
        "                   total=len(df_sample),\n",
        "                   desc=\"Creating documents\",\n",
        "                   position=0,\n",
        "                   leave=True):\n",
        "    try:\n",
        "        # Format text with proper line breaks\n",
        "        text = \"\"\n",
        "\n",
        "        for col in df.columns:\n",
        "            text += f\"{col}: {row[col]}\\n\"\n",
        "\n",
        "        documents.append(Document(page_content=text))\n",
        "\n",
        "    except KeyError as e:\n",
        "        tqdm.write(f\"Missing column: {e}\")\n",
        "    except Exception as e:\n",
        "        tqdm.write(f\"Error processing row: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a88ecf86-c0db-4d5f-9fbe-8f9bdc3052ba",
      "metadata": {
        "id": "a88ecf86-c0db-4d5f-9fbe-8f9bdc3052ba"
      },
      "outputs": [],
      "source": [
        "graph_documents = await llm_transformer.aconvert_to_graph_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1979bc97-bf42-4726-bfed-87bcf8d463f7",
      "metadata": {
        "id": "1979bc97-bf42-4726-bfed-87bcf8d463f7"
      },
      "outputs": [],
      "source": [
        "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
        "print(f\"Relationships:{graph_documents[0].relationships}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e39457b-a2b2-478a-8cb8-ed79916aa90e",
      "metadata": {
        "id": "2e39457b-a2b2-478a-8cb8-ed79916aa90e"
      },
      "outputs": [],
      "source": [
        "graph = Neo4jGraph(url=uri, username=user, password=password, enhanced_schema=True)\n",
        "graph.add_graph_documents(graph_documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d18cf94f-696a-4834-aa28-05e4d3b5415e",
      "metadata": {
        "id": "d18cf94f-696a-4834-aa28-05e4d3b5415e"
      },
      "outputs": [],
      "source": [
        "graph.refresh_schema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d95084f0-a8c6-4e25-a6fc-e6df1e3e57eb",
      "metadata": {
        "id": "d95084f0-a8c6-4e25-a6fc-e6df1e3e57eb"
      },
      "outputs": [],
      "source": [
        "# llm = ChatGoogleGenerativeAI(\n",
        "#     model=\"gemini-1.5-pro\",\n",
        "#     temperature=0,\n",
        "#     max_tokens=None,\n",
        "#     timeout=None,\n",
        "#     max_retries=2,\n",
        "#     api_key=api_key\n",
        "# )\n",
        "\n",
        "CYPHER_GENERATION_TEMPLATE = \"\"\"Task:Generate Cypher statement to query a graph database.\n",
        "Instructions:\n",
        "Use only the provided relationship types and properties in the schema.\n",
        "Do not use any other relationship types or properties that are not provided.\n",
        "Schema:\n",
        "{schema}\n",
        "Note: Do not include any explanations or apologies in your responses.\n",
        "Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
        "Do not include any text except the generated Cypher statement.\n",
        "Return every node as whole, do not return only the properties.\n",
        "\n",
        "The question is:\n",
        "{question}\"\"\"\n",
        "\n",
        "CYPHER_GENERATION_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"schema\", \"question\"], template=CYPHER_GENERATION_TEMPLATE\n",
        ")\n",
        "\n",
        "chain = GraphCypherQAChain.from_llm(\n",
        "    llm,\n",
        "    graph=graph,\n",
        "    verbose=True,\n",
        "    allow_dangerous_requests=True,\n",
        "    return_intermediate_steps=True,\n",
        "    cypher_prompt=CYPHER_GENERATION_PROMPT\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9771960-a156-4315-a7c0-e98b758590d9",
      "metadata": {
        "id": "b9771960-a156-4315-a7c0-e98b758590d9"
      },
      "outputs": [],
      "source": [
        "chain.run(\"Give me an overview of the movie titled David Copperfield.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}