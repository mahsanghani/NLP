{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAdr-Xz4NyGk"
      },
      "outputs": [],
      "source": [
        "!pip install -q opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tf-models-official"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8L1vmhiOqEq",
        "outputId": "0f6f59ce-821a-4a25-ce2a-fe460a61474a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "l6IJWQvMOrBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_models as tfm\n",
        "nlp = tfm.nlp"
      ],
      "metadata": {
        "id": "z0N_eJLHOsg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = {\n",
        "    \"vocab_size\": 100,\n",
        "    \"hidden_size\": 32,\n",
        "    \"num_layers\": 3,\n",
        "    \"num_attention_heads\": 4,\n",
        "    \"intermediate_size\": 64,\n",
        "    \"activation\": tfm.utils.activations.gelu,\n",
        "    \"dropout_rate\": 0.1,\n",
        "    \"attention_dropout_rate\": 0.1,\n",
        "    \"max_sequence_length\": 16,\n",
        "    \"type_vocab_size\": 2,\n",
        "    \"initializer\": tf.keras.initializers.TruncatedNormal(stddev=0.02),\n",
        "}\n",
        "bert_encoder = nlp.networks.BertEncoder(**cfg)\n",
        "\n",
        "def build_classifier(bert_encoder):\n",
        "  return nlp.models.BertClassifier(bert_encoder, num_classes=2)\n",
        "\n",
        "canonical_classifier_model = build_classifier(bert_encoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EHl-RPHOtU8",
        "outputId": "6c235029-def9-4ee5-e971-8238623ac75e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tf_keras/src/initializers/__init__.py:144: UserWarning: The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'keras.src.initializers.random_initializers.TruncatedNormal'>, which may lead to improper serialization.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model):\n",
        "  batch_size = 3\n",
        "  np.random.seed(0)\n",
        "  word_ids = np.random.randint(\n",
        "      cfg[\"vocab_size\"], size=(batch_size, cfg[\"max_sequence_length\"]))\n",
        "  mask = np.random.randint(2, size=(batch_size, cfg[\"max_sequence_length\"]))\n",
        "  type_ids = np.random.randint(\n",
        "      cfg[\"type_vocab_size\"], size=(batch_size, cfg[\"max_sequence_length\"]))\n",
        "  print(model([word_ids, mask, type_ids], training=False))\n",
        "\n",
        "predict(canonical_classifier_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxTjzR-iOucl",
        "outputId": "13c64dd9-3811-4ef9-b278-24dd4ef0bf4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.00606001 -0.0205723 ]\n",
            " [ 0.13570566 -0.20238872]\n",
            " [-0.02476082  0.03767319]], shape=(3, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "default_hidden_cfg = dict(\n",
        "    num_attention_heads=cfg[\"num_attention_heads\"],\n",
        "    intermediate_size=cfg[\"intermediate_size\"],\n",
        "    intermediate_activation=cfg[\"activation\"],\n",
        "    dropout_rate=cfg[\"dropout_rate\"],\n",
        "    attention_dropout_rate=cfg[\"attention_dropout_rate\"],\n",
        "    kernel_initializer=cfg[\"initializer\"],\n",
        ")"
      ],
      "metadata": {
        "id": "Wa9-dlrdOvlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_embedding_cfg = dict(\n",
        "    vocab_size=cfg[\"vocab_size\"],\n",
        "    type_vocab_size=cfg[\"type_vocab_size\"],\n",
        "    hidden_size=cfg[\"hidden_size\"],\n",
        "    initializer=cfg[\"initializer\"],\n",
        "    dropout_rate=cfg[\"dropout_rate\"],\n",
        "    max_seq_length=cfg[\"max_sequence_length\"]\n",
        ")"
      ],
      "metadata": {
        "id": "VYB2QKmSOx8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_kwargs = dict(\n",
        "    hidden_cfg=default_hidden_cfg,\n",
        "    embedding_cfg=default_embedding_cfg,\n",
        "    num_hidden_instances=cfg[\"num_layers\"],\n",
        "    pooled_output_dim=cfg[\"hidden_size\"],\n",
        "    return_all_layer_outputs=True,\n",
        "    pooler_layer_initializer=cfg[\"initializer\"],\n",
        ")"
      ],
      "metadata": {
        "id": "MtmvXxMDOzdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_scaffold = nlp.networks.EncoderScaffold(**default_kwargs)\n",
        "classifier_model_from_encoder_scaffold = build_classifier(encoder_scaffold)\n",
        "classifier_model_from_encoder_scaffold.set_weights(\n",
        "    canonical_classifier_model.get_weights())\n",
        "predict(classifier_model_from_encoder_scaffold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfUhzTEhO0Sv",
        "outputId": "a039c591-cfeb-467f-c3ce-d526c123e3d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:The `Transformer` layer is deprecated. Please directly use `TransformerEncoderBlock`.\n",
            "WARNING:absl:The `Transformer` layer is deprecated. Please directly use `TransformerEncoderBlock`.\n",
            "WARNING:absl:The `Transformer` layer is deprecated. Please directly use `TransformerEncoderBlock`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.00606001 -0.0205723 ]\n",
            " [ 0.13570566 -0.20238872]\n",
            " [-0.02476082  0.03767319]], shape=(3, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyOnDeviceEmbedding(tf.keras.layers.Layer):\n",
        "  \"\"\"Performs an embedding lookup suitable for accelerator devices.\n",
        "\n",
        "  This layer uses either tf.gather or tf.one_hot to translate integer indices to\n",
        "  float embeddings.\n",
        "\n",
        "  Args:\n",
        "    vocab_size: Number of elements in the vocabulary.\n",
        "    embedding_width: Output size of the embedding layer.\n",
        "    initializer: The initializer to use for the embedding weights. Defaults to\n",
        "      \"glorot_uniform\".\n",
        "    use_one_hot: Whether to use tf.one_hot over tf.gather for the embedding\n",
        "      lookup. Defaults to False (that is, using tf.gather). Setting this option\n",
        "      to True may improve performance, especially on small vocabulary sizes, but\n",
        "      will generally require more memory.\n",
        "    scale_factor: Whether to scale the output embeddings. Defaults to None (that\n",
        "      is, not to scale). Setting this option to a float will let values in\n",
        "      output embeddings multiplied by scale_factor.\n",
        "    weight_fallback_dtype: When keras mix precision inferred wrong dtype for\n",
        "      variables, `weight_fallback_dtype` will be used to define the dtype of\n",
        "      weights.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               vocab_size,\n",
        "               embedding_width,\n",
        "               initializer=\"glorot_uniform\",\n",
        "               use_one_hot=False,\n",
        "               scale_factor=None,\n",
        "               weight_fallback_dtype=tf.float32,\n",
        "               **kwargs):\n",
        "\n",
        "    super().__init__(**kwargs)\n",
        "    self._vocab_size = vocab_size\n",
        "    self._embedding_width = embedding_width\n",
        "    self._initializer = initializer\n",
        "    self._use_one_hot = use_one_hot\n",
        "    self._scale_factor = scale_factor\n",
        "    # Backup control of the weight dtype because Keras mix precision sometimes\n",
        "    # depends on the input to infer the compute dtype, but the inputs of\n",
        "    # this layer are int type.\n",
        "    self._weight_fallback_dtype = weight_fallback_dtype\n",
        "\n",
        "  def get_config(self):\n",
        "    config = {\n",
        "        \"vocab_size\": self._vocab_size,\n",
        "        \"embedding_width\": self._embedding_width,\n",
        "        \"initializer\": self._initializer,\n",
        "        \"use_one_hot\": self._use_one_hot,\n",
        "        \"scale_factor\": self._scale_factor,\n",
        "        \"weight_fallback_dtype\": self._weight_fallback_dtype,\n",
        "    }\n",
        "    base_config = super().get_config()\n",
        "    return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    if (\n",
        "        self.dtype is not None\n",
        "        and not tf.dtypes.as_dtype(self.dtype).is_floating\n",
        "    ):\n",
        "      # Keras failed to infer the right dtype.\n",
        "      dtype = self._weight_fallback_dtype\n",
        "    else:\n",
        "      dtype = self.dtype\n",
        "    self.embeddings = self.add_weight(\n",
        "        \"embeddings\",\n",
        "        shape=[self._vocab_size, self._embedding_width],\n",
        "        initializer=self._initializer,\n",
        "        dtype=dtype)\n",
        "\n",
        "    super().build(input_shape)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    flat_inputs = tf.reshape(inputs, [-1])\n",
        "    if self._use_one_hot:\n",
        "      dtype = self.compute_dtype\n",
        "      if not tf.dtypes.as_dtype(dtype).is_floating:\n",
        "        # TensorFlow 1 compatibility. In TF1, self.compute_dtype is int32\n",
        "        # instead of a floating-point dtype, as the dtype is inferred from the\n",
        "        # dtype of the inputs\n",
        "        dtype = self._weight_fallback_dtype\n",
        "      one_hot_data = tf.one_hot(\n",
        "          flat_inputs, depth=self._vocab_size, dtype=dtype)\n",
        "      embeddings = tf.matmul(one_hot_data, self.embeddings)\n",
        "    else:\n",
        "      embeddings = tf.gather(self.embeddings, flat_inputs)\n",
        "    embeddings = tf.reshape(\n",
        "        embeddings,\n",
        "        tf.concat([tf.shape(inputs), [self._embedding_width]], axis=0))\n",
        "    embeddings.set_shape(inputs.shape.as_list() + [self._embedding_width])\n",
        "    if self._scale_factor:\n",
        "      embeddings *= self._scale_factor\n",
        "    return embeddings\n",
        "\n",
        "  @property\n",
        "  def vocab_size(self):\n",
        "    return self._vocab_size\n",
        "\n",
        "  @property\n",
        "  def embedding_width(self):\n",
        "    return self._embedding_width"
      ],
      "metadata": {
        "id": "MxHYK-NEgbvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wSAKHZ3HZssa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}