{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAdr-Xz4NyGk"
      },
      "outputs": [],
      "source": [
        "!pip install -q opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tf-models-official"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8L1vmhiOqEq",
        "outputId": "0f6f59ce-821a-4a25-ce2a-fe460a61474a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "l6IJWQvMOrBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_models as tfm\n",
        "nlp = tfm.nlp"
      ],
      "metadata": {
        "id": "z0N_eJLHOsg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = {\n",
        "    \"vocab_size\": 100,\n",
        "    \"hidden_size\": 32,\n",
        "    \"num_layers\": 3,\n",
        "    \"num_attention_heads\": 4,\n",
        "    \"intermediate_size\": 64,\n",
        "    \"activation\": tfm.utils.activations.gelu,\n",
        "    \"dropout_rate\": 0.1,\n",
        "    \"attention_dropout_rate\": 0.1,\n",
        "    \"max_sequence_length\": 16,\n",
        "    \"type_vocab_size\": 2,\n",
        "    \"initializer\": tf.keras.initializers.TruncatedNormal(stddev=0.02),\n",
        "}\n",
        "bert_encoder = nlp.networks.BertEncoder(**cfg)\n",
        "\n",
        "def build_classifier(bert_encoder):\n",
        "  return nlp.models.BertClassifier(bert_encoder, num_classes=2)\n",
        "\n",
        "canonical_classifier_model = build_classifier(bert_encoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EHl-RPHOtU8",
        "outputId": "6c235029-def9-4ee5-e971-8238623ac75e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tf_keras/src/initializers/__init__.py:144: UserWarning: The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'keras.src.initializers.random_initializers.TruncatedNormal'>, which may lead to improper serialization.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model):\n",
        "  batch_size = 3\n",
        "  np.random.seed(0)\n",
        "  word_ids = np.random.randint(\n",
        "      cfg[\"vocab_size\"], size=(batch_size, cfg[\"max_sequence_length\"]))\n",
        "  mask = np.random.randint(2, size=(batch_size, cfg[\"max_sequence_length\"]))\n",
        "  type_ids = np.random.randint(\n",
        "      cfg[\"type_vocab_size\"], size=(batch_size, cfg[\"max_sequence_length\"]))\n",
        "  print(model([word_ids, mask, type_ids], training=False))\n",
        "\n",
        "predict(canonical_classifier_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxTjzR-iOucl",
        "outputId": "13c64dd9-3811-4ef9-b278-24dd4ef0bf4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.00606001 -0.0205723 ]\n",
            " [ 0.13570566 -0.20238872]\n",
            " [-0.02476082  0.03767319]], shape=(3, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "default_hidden_cfg = dict(\n",
        "    num_attention_heads=cfg[\"num_attention_heads\"],\n",
        "    intermediate_size=cfg[\"intermediate_size\"],\n",
        "    intermediate_activation=cfg[\"activation\"],\n",
        "    dropout_rate=cfg[\"dropout_rate\"],\n",
        "    attention_dropout_rate=cfg[\"attention_dropout_rate\"],\n",
        "    kernel_initializer=cfg[\"initializer\"],\n",
        ")"
      ],
      "metadata": {
        "id": "Wa9-dlrdOvlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_embedding_cfg = dict(\n",
        "    vocab_size=cfg[\"vocab_size\"],\n",
        "    type_vocab_size=cfg[\"type_vocab_size\"],\n",
        "    hidden_size=cfg[\"hidden_size\"],\n",
        "    initializer=cfg[\"initializer\"],\n",
        "    dropout_rate=cfg[\"dropout_rate\"],\n",
        "    max_seq_length=cfg[\"max_sequence_length\"]\n",
        ")"
      ],
      "metadata": {
        "id": "VYB2QKmSOx8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_kwargs = dict(\n",
        "    hidden_cfg=default_hidden_cfg,\n",
        "    embedding_cfg=default_embedding_cfg,\n",
        "    num_hidden_instances=cfg[\"num_layers\"],\n",
        "    pooled_output_dim=cfg[\"hidden_size\"],\n",
        "    return_all_layer_outputs=True,\n",
        "    pooler_layer_initializer=cfg[\"initializer\"],\n",
        ")"
      ],
      "metadata": {
        "id": "MtmvXxMDOzdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_scaffold = nlp.networks.EncoderScaffold(**default_kwargs)\n",
        "classifier_model_from_encoder_scaffold = build_classifier(encoder_scaffold)\n",
        "classifier_model_from_encoder_scaffold.set_weights(\n",
        "    canonical_classifier_model.get_weights())\n",
        "predict(classifier_model_from_encoder_scaffold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfUhzTEhO0Sv",
        "outputId": "a039c591-cfeb-467f-c3ce-d526c123e3d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:The `Transformer` layer is deprecated. Please directly use `TransformerEncoderBlock`.\n",
            "WARNING:absl:The `Transformer` layer is deprecated. Please directly use `TransformerEncoderBlock`.\n",
            "WARNING:absl:The `Transformer` layer is deprecated. Please directly use `TransformerEncoderBlock`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.00606001 -0.0205723 ]\n",
            " [ 0.13570566 -0.20238872]\n",
            " [-0.02476082  0.03767319]], shape=(3, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyOnDeviceEmbedding(tf.keras.layers.Layer):\n",
        "  \"\"\"Performs an embedding lookup suitable for accelerator devices.\n",
        "\n",
        "  This layer uses either tf.gather or tf.one_hot to translate integer indices to\n",
        "  float embeddings.\n",
        "\n",
        "  Args:\n",
        "    vocab_size: Number of elements in the vocabulary.\n",
        "    embedding_width: Output size of the embedding layer.\n",
        "    initializer: The initializer to use for the embedding weights. Defaults to\n",
        "      \"glorot_uniform\".\n",
        "    use_one_hot: Whether to use tf.one_hot over tf.gather for the embedding\n",
        "      lookup. Defaults to False (that is, using tf.gather). Setting this option\n",
        "      to True may improve performance, especially on small vocabulary sizes, but\n",
        "      will generally require more memory.\n",
        "    scale_factor: Whether to scale the output embeddings. Defaults to None (that\n",
        "      is, not to scale). Setting this option to a float will let values in\n",
        "      output embeddings multiplied by scale_factor.\n",
        "    weight_fallback_dtype: When keras mix precision inferred wrong dtype for\n",
        "      variables, `weight_fallback_dtype` will be used to define the dtype of\n",
        "      weights.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               vocab_size,\n",
        "               embedding_width,\n",
        "               initializer=\"glorot_uniform\",\n",
        "               use_one_hot=False,\n",
        "               scale_factor=None,\n",
        "               weight_fallback_dtype=tf.float32,\n",
        "               **kwargs):\n",
        "\n",
        "    super().__init__(**kwargs)\n",
        "    self._vocab_size = vocab_size\n",
        "    self._embedding_width = embedding_width\n",
        "    self._initializer = initializer\n",
        "    self._use_one_hot = use_one_hot\n",
        "    self._scale_factor = scale_factor\n",
        "    # Backup control of the weight dtype because Keras mix precision sometimes\n",
        "    # depends on the input to infer the compute dtype, but the inputs of\n",
        "    # this layer are int type.\n",
        "    self._weight_fallback_dtype = weight_fallback_dtype\n",
        "\n",
        "  def get_config(self):\n",
        "    config = {\n",
        "        \"vocab_size\": self._vocab_size,\n",
        "        \"embedding_width\": self._embedding_width,\n",
        "        \"initializer\": self._initializer,\n",
        "        \"use_one_hot\": self._use_one_hot,\n",
        "        \"scale_factor\": self._scale_factor,\n",
        "        \"weight_fallback_dtype\": self._weight_fallback_dtype,\n",
        "    }\n",
        "    base_config = super().get_config()\n",
        "    return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    if (\n",
        "        self.dtype is not None\n",
        "        and not tf.dtypes.as_dtype(self.dtype).is_floating\n",
        "    ):\n",
        "      # Keras failed to infer the right dtype.\n",
        "      dtype = self._weight_fallback_dtype\n",
        "    else:\n",
        "      dtype = self.dtype\n",
        "    self.embeddings = self.add_weight(\n",
        "        \"embeddings\",\n",
        "        shape=[self._vocab_size, self._embedding_width],\n",
        "        initializer=self._initializer,\n",
        "        dtype=dtype)\n",
        "\n",
        "    super().build(input_shape)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    flat_inputs = tf.reshape(inputs, [-1])\n",
        "    if self._use_one_hot:\n",
        "      dtype = self.compute_dtype\n",
        "      if not tf.dtypes.as_dtype(dtype).is_floating:\n",
        "        # TensorFlow 1 compatibility. In TF1, self.compute_dtype is int32\n",
        "        # instead of a floating-point dtype, as the dtype is inferred from the\n",
        "        # dtype of the inputs\n",
        "        dtype = self._weight_fallback_dtype\n",
        "      one_hot_data = tf.one_hot(\n",
        "          flat_inputs, depth=self._vocab_size, dtype=dtype)\n",
        "      embeddings = tf.matmul(one_hot_data, self.embeddings)\n",
        "    else:\n",
        "      embeddings = tf.gather(self.embeddings, flat_inputs)\n",
        "    embeddings = tf.reshape(\n",
        "        embeddings,\n",
        "        tf.concat([tf.shape(inputs), [self._embedding_width]], axis=0))\n",
        "    embeddings.set_shape(inputs.shape.as_list() + [self._embedding_width])\n",
        "    if self._scale_factor:\n",
        "      embeddings *= self._scale_factor\n",
        "    return embeddings\n",
        "\n",
        "  @property\n",
        "  def vocab_size(self):\n",
        "    return self._vocab_size\n",
        "\n",
        "  @property\n",
        "  def embedding_width(self):\n",
        "    return self._embedding_width"
      ],
      "metadata": {
        "id": "MxHYK-NEgbvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg['max_sequence_length']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZbwfFQLiz6L",
        "outputId": "58cc9fd2-791f-4bb5-a1b3-a071c1bb9214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_ids = tf.keras.layers.Input(\n",
        "    shape=(cfg['max_sequence_length'],),\n",
        "    dtype=tf.int32,\n",
        "    name=\"input_word_ids\")\n",
        "\n",
        "mask = tf.keras.layers.Input(\n",
        "    shape=(cfg['max_sequence_length'],),\n",
        "    dtype=tf.int32, name=\"input_mask\")\n",
        "\n",
        "embedding_layer = MyOnDeviceEmbedding(\n",
        "    vocab_size=cfg['vocab_size'],\n",
        "    embedding_width=cfg['hidden_size'],\n",
        "    initializer=cfg[\"initializer\"],\n",
        "    name=\"word_embeddings\")\n",
        "word_embeddings = embedding_layer(word_ids)\n",
        "attention_mask = nlp.layers.SelfAttentionMask()([word_embeddings, mask])\n",
        "new_embedding_network = tf.keras.Model([word_ids, mask],\n",
        "                                       [word_embeddings, attention_mask])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "RJV-EKSlbqhu",
        "outputId": "d4e55203-c77a-426b-9c49-7663b66737f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Layer.add_weight() got multiple values for argument 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-7794060ddd53>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initializer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     name=\"word_embeddings\")\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mword_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSelfAttentionMask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m new_embedding_network = tf.keras.Model([word_ids, mask],\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-b5c8a49df90b>\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     self.embeddings = self.add_weight(\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;34m\"embeddings\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embedding_width\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Layer.add_weight() got multiple values for argument 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class MyOnDeviceEmbedding(tf.keras.layers.Layer):\n",
        "#     def __init__(self, vocab_size, embedding_width, initializer, name=None):\n",
        "#         super(MyOnDeviceEmbedding, self).__init__(name=name)\n",
        "#         self.vocab_size = vocab_size\n",
        "#         self.embedding_width = embedding_width\n",
        "#         self.initializer = initializer\n",
        "\n",
        "#     def build(self, input_shape):\n",
        "#         # Initialize the embedding layer in build method\n",
        "#         self.embedding_layer = nlp.layers.OnDeviceEmbedding(\n",
        "#             vocab_size=self.vocab_size,\n",
        "#             embedding_width=self.embedding_width,\n",
        "#             initializer=self.initializer\n",
        "#         )\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         # Apply the embedding layer to the inputs\n",
        "#         return self.embedding_layer(inputs)\n",
        "\n",
        "#     def build(self, input_shape):\n",
        "#         if (\n",
        "#             self.dtype is not None\n",
        "#             and not tf.dtypes.as_dtype(self.dtype).is_floating\n",
        "#         ):\n",
        "#           # Keras failed to infer the right dtype.\n",
        "#           dtype = self.weight_fallback_dtype\n",
        "#         else:\n",
        "#           dtype = self.dtype\n",
        "#         self.embeddings = self.add_weight(\n",
        "#             \"embeddings\",\n",
        "#             shape=[self.vocab_size, self.embedding_width],\n",
        "#             initializer=self.initializer,\n",
        "#             dtype=dtype)\n",
        "\n",
        "#         super().build(input_shape)\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         flat_inputs = tf.reshape(inputs, [-1])\n",
        "#         if self._use_one_hot:\n",
        "#           dtype = self.compute_dtype\n",
        "#           if not tf.dtypes.as_dtype(dtype).is_floating:\n",
        "#             # TensorFlow 1 compatibility. In TF1, self.compute_dtype is int32\n",
        "#             # instead of a floating-point dtype, as the dtype is inferred from the\n",
        "#             # dtype of the inputs\n",
        "#             dtype = self._weight_fallback_dtype\n",
        "#           one_hot_data = tf.one_hot(\n",
        "#               flat_inputs, depth=self.vocab_size, dtype=dtype)\n",
        "#           embeddings = tf.matmul(one_hot_data, self.embeddings)\n",
        "#         else:\n",
        "#           embeddings = tf.gather(self.embeddings, flat_inputs)\n",
        "#         embeddings = tf.reshape(\n",
        "#             embeddings,\n",
        "#             tf.concat([tf.shape(inputs), [self.embedding_width]], axis=0))\n",
        "#         embeddings.set_shape(inputs.shape.as_list() + [self.embedding_width])\n",
        "#         if self.scale_factor:\n",
        "#           embeddings *= self.scale_factor\n",
        "#         return embeddings\n",
        "\n",
        "# # Example usage\n",
        "# word_ids = tf.keras.layers.Input(\n",
        "#     shape=(cfg['max_sequence_length'],), dtype=tf.int32, name=\"input_word_ids\")\n",
        "# mask = tf.keras.layers.Input(\n",
        "#     shape=(cfg['max_sequence_length'],), dtype=tf.int32, name=\"input_mask\")\n",
        "\n",
        "# # Use the custom embedding layer\n",
        "# embedding_layer = MyOnDeviceEmbedding(\n",
        "#     vocab_size=cfg['vocab_size'],\n",
        "#     embedding_width=cfg['hidden_size'],\n",
        "#     initializer=cfg[\"initializer\"],\n",
        "#     name=\"word_embeddings\"\n",
        "# )"
      ],
      "metadata": {
        "id": "HsuCVGTQP69j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class CustomAttentionMask(tf.keras.layers.Layer):\n",
        "#     def call(self, inputs):\n",
        "#         word_embeddings, mask = inputs\n",
        "#         mask = tf.cast(tf.expand_dims(mask, axis=-1), dtype=word_embeddings.dtype)\n",
        "#         return mask * word_embeddings\n",
        "\n",
        "# # Apply embedding layer\n",
        "# word_embeddings = embedding_layer(word_ids)\n",
        "\n",
        "# # Apply the custom attention mask\n",
        "# attention_mask = CustomAttentionMask()([word_embeddings, mask])\n",
        "\n",
        "# # Create the Keras model\n",
        "# new_embedding_network = tf.keras.Model([word_ids, mask], [word_embeddings, attention_mask])"
      ],
      "metadata": {
        "id": "Olhz3PkbZ0xI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Word Embeddings Shape: {word_embeddings.shape}\")\n",
        "print(f\"Attention Mask Shape: {attention_mask.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YoCsJIgVMH3",
        "outputId": "0d0c3f52-e889-4654-8d76-412c0554590a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Embeddings Shape: (None, 16, 32)\n",
            "Attention Mask Shape: (None, 16, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(new_embedding_network, show_shapes=True, dpi=48)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "jAw1DuyeO5Bc",
        "outputId": "003319c3-e707-4f93-8c8e-1d952bee0be6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kwargs = dict(default_kwargs)\n",
        "\n",
        "# Use new embedding network.\n",
        "kwargs['embedding_cls'] = new_embedding_network\n",
        "kwargs['embedding_data'] = embedding_layer.embeddings\n",
        "\n",
        "encoder_with_customized_embedding = nlp.networks.EncoderScaffold(**kwargs)\n",
        "classifier_model = build_classifier(encoder_with_customized_embedding)\n",
        "# ... Train the model ...\n",
        "print(classifier_model.inputs)\n",
        "\n",
        "# Assert that there are only two inputs.\n",
        "assert len(classifier_model.inputs) == 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "0NhDTF4eO6kf",
        "outputId": "ea3a6577-7530-46ab-f3ec-98217dd1f83d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MyOnDeviceEmbedding' object has no attribute 'embeddings'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-e8379c9534dd>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Use new embedding network.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'embedding_cls'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_embedding_network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'embedding_data'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mencoder_with_customized_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetworks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEncoderScaffold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'MyOnDeviceEmbedding' object has no attribute 'embeddings'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_mask = nlp.layers.SelfAttentionMask()([mask])"
      ],
      "metadata": {
        "id": "ZR1P6-cRRR3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the mask to match the word_embeddings shape\n",
        "mask_expanded = tf.expand_dims(mask, axis=-1)\n",
        "\n",
        "# Apply the attention mask\n",
        "attention_mask = nlp.layers.SelfAttentionMask()([word_embeddings, mask_expanded])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "eMWL3I8JZozR",
        "outputId": "30cff455-d001-46c9-ea83-efe389478a80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-22afe1456269>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Reshape the mask to match the word_embeddings shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmask_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Apply the attention mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSelfAttentionMask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_expanded\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py\u001b[0m in \u001b[0;36m__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__tf_tensor__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0;34m\"A KerasTensor cannot be used as input to a TensorFlow function. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;34m\"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomAttentionMask(tf.keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        word_embeddings, mask = inputs\n",
        "        mask = tf.cast(tf.expand_dims(mask, axis=-1), dtype=word_embeddings.dtype)\n",
        "        return mask * word_embeddings\n",
        "\n",
        "# Apply the custom attention mask\n",
        "attention_mask = CustomAttentionMask()([word_embeddings, mask])\n"
      ],
      "metadata": {
        "id": "rZ2ev9HlZq7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wSAKHZ3HZssa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}