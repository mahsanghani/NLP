{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4TvPXaMFaI_",
        "outputId": "62fb8c6f-4999-4338-c02b-0bd26ca122ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-aiplatform 1.64.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.15.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigtable 2.26.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-functions 1.16.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-iam 2.15.2 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-language 2.13.4 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-pubsub 2.23.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-resource-manager 1.12.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-translate 3.15.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "googleapis-common-protos 1.65.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpc-google-iam-v1 0.13.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "pandas-gbq 0.23.1 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.6 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q -U \"tensorflow-text==2.11.*\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_text as text\n",
        "import functools\n",
        "print(\"TensorFlow version: \", tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUM6XFDmFdO4",
        "outputId": "02fd6909-3c8f-4e09-dfd7-919d2cbed2f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version:  2.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examples = {\n",
        "    \"text_a\": [\n",
        "      \"Sponge bob Squarepants is an Avenger\",\n",
        "      \"Marvel Avengers\"\n",
        "    ],\n",
        "    \"text_b\": [\n",
        "     \"Barack Obama is the President.\",\n",
        "     \"President is the highest office\"\n",
        "  ],\n",
        "}\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(examples)\n",
        "next(iter(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KowK_aR6Fd8I",
        "outputId": "35def254-f1aa-43ca-aeca-0f437ed800e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text_a': <tf.Tensor: shape=(), dtype=string, numpy=b'Sponge bob Squarepants is an Avenger'>,\n",
              " 'text_b': <tf.Tensor: shape=(), dtype=string, numpy=b'Barack Obama is the President.'>}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_VOCAB = [\n",
        "    # Special tokens\n",
        "    b\"[UNK]\", b\"[MASK]\", b\"[RANDOM]\", b\"[CLS]\", b\"[SEP]\",\n",
        "    # Suffixes\n",
        "    b\"##ack\", b\"##ama\", b\"##ger\", b\"##gers\", b\"##onge\", b\"##pants\",  b\"##uare\",\n",
        "    b\"##vel\", b\"##ven\", b\"an\", b\"A\", b\"Bar\", b\"Hates\", b\"Mar\", b\"Ob\",\n",
        "    b\"Patrick\", b\"President\", b\"Sp\", b\"Sq\", b\"bob\", b\"box\", b\"has\", b\"highest\",\n",
        "    b\"is\", b\"office\", b\"the\",\n",
        "]\n",
        "\n",
        "_START_TOKEN = _VOCAB.index(b\"[CLS]\")\n",
        "_END_TOKEN = _VOCAB.index(b\"[SEP]\")\n",
        "_MASK_TOKEN = _VOCAB.index(b\"[MASK]\")\n",
        "_RANDOM_TOKEN = _VOCAB.index(b\"[RANDOM]\")\n",
        "_UNK_TOKEN = _VOCAB.index(b\"[UNK]\")\n",
        "_MAX_SEQ_LEN = 8\n",
        "_MAX_PREDICTIONS_PER_BATCH = 5\n",
        "\n",
        "_VOCAB_SIZE = len(_VOCAB)\n",
        "\n",
        "lookup_table = tf.lookup.StaticVocabularyTable(\n",
        "    tf.lookup.KeyValueTensorInitializer(\n",
        "      keys=_VOCAB,\n",
        "      key_dtype=tf.string,\n",
        "      values=tf.range(\n",
        "          tf.size(_VOCAB, out_type=tf.int64), dtype=tf.int64),\n",
        "          value_dtype=tf.int64\n",
        "        ),\n",
        "      num_oov_buckets=1\n",
        ")"
      ],
      "metadata": {
        "id": "wP-JhUrnFf_I"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_tokenizer = text.BertTokenizer(lookup_table, token_out_type=tf.string)\n",
        "bert_tokenizer.tokenize(examples[\"text_a\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcOmwspyFhBw",
        "outputId": "9451f083-95ec-4b33-ab86-c385f2d9b2d9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[[b'Sp', b'##onge'], [b'bob'], [b'Sq', b'##uare', b'##pants'], [b'is'],\n",
              "  [b'an'], [b'A', b'##ven', b'##ger']]                                  ,\n",
              " [[b'Mar', b'##vel'], [b'A', b'##ven', b'##gers']]]>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_tokenizer.tokenize(examples[\"text_b\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxkRiUfZFiVn",
        "outputId": "a16c7975-32ac-44ae-a7d2-e248361abdf1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[[b'Bar', b'##ack'], [b'Ob', b'##ama'], [b'is'], [b'the'], [b'President'],\n",
              "  [b'[UNK]']]                                                              ,\n",
              " [[b'President'], [b'is'], [b'the'], [b'highest'], [b'office']]]>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_tokenizer = text.BertTokenizer(lookup_table, token_out_type=tf.int64)\n",
        "segment_a = bert_tokenizer.tokenize(examples[\"text_a\"])\n",
        "segment_a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Znb6HVyRFjB6",
        "outputId": "549c0d22-de8e-4127-c6a6-d5f8599c1525"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[[22, 9], [24], [23, 11, 10], [28], [14], [15, 13, 7]],\n",
              " [[18, 12], [15, 13, 8]]]>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "segment_b = bert_tokenizer.tokenize(examples[\"text_b\"])\n",
        "segment_b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C955ukj2FtSL",
        "outputId": "00973609-86d4-46b8-b4a8-5fcbb844b3ab"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[[16, 5], [19, 6], [28], [30], [21], [0]], [[21], [28], [30], [27], [29]]]>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "segment_a = segment_a.merge_dims(-2, -1)\n",
        "segment_a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhOlJz6EFt71",
        "outputId": "9663c3e8-e35e-4267-f463-95cccb6a6479"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[22, 9, 24, 23, 11, 10, 28, 14, 15, 13, 7], [18, 12, 15, 13, 8]]>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "segment_b = segment_b.merge_dims(-2, -1)\n",
        "segment_b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZg4V9rFFuzF",
        "outputId": "bed280c2-7172-44f0-d036-0b561d1799aa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[16, 5, 19, 6, 28, 30, 21, 0], [21, 28, 30, 27, 29]]>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trimmer = text.RoundRobinTrimmer(max_seq_length=_MAX_SEQ_LEN)\n",
        "trimmed = trimmer.trim([segment_a, segment_b])\n",
        "trimmed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_yv_7UUFwgJ",
        "outputId": "78ae83e6-c67b-4a06-ec01-b286a281ed91"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.RaggedTensor [[22, 9, 24, 23],\n",
              "  [18, 12, 15, 13]]>,\n",
              " <tf.RaggedTensor [[16, 5, 19, 6],\n",
              "  [21, 28, 30, 27]]>]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "segments_combined, segments_ids = text.combine_segments(\n",
        "  trimmed,\n",
        "  start_of_sequence_id=_START_TOKEN, end_of_segment_id=_END_TOKEN)\n",
        "segments_combined, segments_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20H78XxRF2LL",
        "outputId": "cc7e860f-f6d0-4634-ca61-5dd23a27cb00"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.RaggedTensor [[3, 22, 9, 24, 23, 4, 16, 5, 19, 6, 4],\n",
              "  [3, 18, 12, 15, 13, 4, 21, 28, 30, 27, 4]]>,\n",
              " <tf.RaggedTensor [[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
              "  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]]>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_selector = text.RandomItemSelector(\n",
        "    max_selections_per_batch=_MAX_PREDICTIONS_PER_BATCH,\n",
        "    selection_rate=0.2,\n",
        "    unselectable_ids=[_START_TOKEN, _END_TOKEN, _UNK_TOKEN]\n",
        ")\n",
        "selected = random_selector.get_selection_mask(\n",
        "    segments_combined, axis=1)\n",
        "selected"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seSE1gubF3E1",
        "outputId": "04964780-8cec-41f1-cd91-5a0b43bbf62e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[False, False, True, False, False, False, True, False, False, False,\n",
              "  False],\n",
              " [False, False, False, False, False, False, False, True, False, True,\n",
              "  False]]>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask_values_chooser = text.MaskValuesChooser(_VOCAB_SIZE, _MASK_TOKEN, 0.8)\n",
        "mask_values_chooser.get_mask_values(segments_combined)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgAyc5ZYF4wH",
        "outputId": "646531c9-850b-4004-cc1c-c34aebe94d2a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[26, 22, 1, 24, 1, 1, 1, 1, 1, 1, 1],\n",
              " [1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1]]>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_token_ids, masked_pos, masked_lm_ids = text.mask_language_model(\n",
        "  segments_combined,\n",
        "  item_selector=random_selector, mask_values_chooser=mask_values_chooser)"
      ],
      "metadata": {
        "id": "7WYWFa9PF77x"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masked_token_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOBryXV0HjEW",
        "outputId": "135c2ace-e95e-4601-a521-8f9419dd8bb0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[3, 22, 9, 24, 1, 4, 16, 5, 1, 6, 4],\n",
              " [3, 1, 12, 15, 13, 4, 17, 28, 30, 27, 4]]>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.gather(_VOCAB, masked_token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyB4Or20HkIj",
        "outputId": "5c36687e-412a-415c-e21e-95aaa24c57a2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'[CLS]', b'Sp', b'##onge', b'bob', b'[MASK]', b'[SEP]', b'Bar',\n",
              "  b'##ack', b'[MASK]', b'##ama', b'[SEP]'],\n",
              " [b'[CLS]', b'[MASK]', b'##vel', b'A', b'##ven', b'[SEP]', b'Hates',\n",
              "  b'is', b'the', b'highest', b'[SEP]']]>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_pos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXf9KhXwHlFQ",
        "outputId": "2605e2ed-8719-4e82-fb58-6e6038296214"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[4, 8],\n",
              " [1, 6]]>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_lm_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYNDnXsPHodl",
        "outputId": "f06ef443-b329-4979-9c4d-79205ff2f98f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[23, 19],\n",
              " [18, 21]]>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.gather(_VOCAB, masked_lm_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ywjRevBHpJq",
        "outputId": "49509296-6b3f-4af5-f2d2-2bd2372f4008"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'Sq', b'Ob'],\n",
              " [b'Mar', b'President']]>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare and pad combined segment inputs\n",
        "input_word_ids, input_mask = text.pad_model_inputs(\n",
        "  masked_token_ids, max_seq_length=_MAX_SEQ_LEN)\n",
        "input_type_ids, _ = text.pad_model_inputs(\n",
        "  segments_ids, max_seq_length=_MAX_SEQ_LEN)"
      ],
      "metadata": {
        "id": "gfHqht8kHrI-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare and pad masking task inputs\n",
        "masked_lm_positions, masked_lm_weights = text.pad_model_inputs(\n",
        "  masked_pos, max_seq_length=_MAX_PREDICTIONS_PER_BATCH)\n",
        "masked_lm_ids, _ = text.pad_model_inputs(\n",
        "  masked_lm_ids, max_seq_length=_MAX_PREDICTIONS_PER_BATCH)"
      ],
      "metadata": {
        "id": "AB0ELsYSHtJH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_inputs = {\n",
        "    \"input_word_ids\": input_word_ids,\n",
        "    \"input_mask\": input_mask,\n",
        "    \"input_type_ids\": input_type_ids,\n",
        "    \"masked_lm_ids\": masked_lm_ids,\n",
        "    \"masked_lm_positions\": masked_lm_positions,\n",
        "    \"masked_lm_weights\": masked_lm_weights,\n",
        "}\n",
        "model_inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgakpQc5HuJj",
        "outputId": "2e6e72fa-0825-4e70-f50d-a1d8abc984c3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_word_ids': <tf.Tensor: shape=(2, 8), dtype=int64, numpy=\n",
              " array([[ 3, 22,  9, 24,  1,  4, 16,  5],\n",
              "        [ 3,  1, 12, 15, 13,  4, 17, 28]])>,\n",
              " 'input_mask': <tf.Tensor: shape=(2, 8), dtype=int64, numpy=\n",
              " array([[1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1]])>,\n",
              " 'input_type_ids': <tf.Tensor: shape=(2, 8), dtype=int64, numpy=\n",
              " array([[0, 0, 0, 0, 0, 0, 1, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 1, 1]])>,\n",
              " 'masked_lm_ids': <tf.Tensor: shape=(2, 5), dtype=int64, numpy=\n",
              " array([[23, 19,  0,  0,  0],\n",
              "        [18, 21,  0,  0,  0]])>,\n",
              " 'masked_lm_positions': <tf.Tensor: shape=(2, 5), dtype=int64, numpy=\n",
              " array([[4, 8, 0, 0, 0],\n",
              "        [1, 6, 0, 0, 0]])>,\n",
              " 'masked_lm_weights': <tf.Tensor: shape=(2, 5), dtype=int64, numpy=\n",
              " array([[1, 1, 0, 0, 0],\n",
              "        [1, 1, 0, 0, 0]])>}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bert_pretrain_preprocess(vocab_table, features):\n",
        "  # Input is a string Tensor of documents, shape [batch, 1].\n",
        "  text_a = features[\"text_a\"]\n",
        "  text_b = features[\"text_b\"]\n",
        "\n",
        "  # Tokenize segments to shape [num_sentences, (num_words)] each.\n",
        "  tokenizer = text.BertTokenizer(\n",
        "      vocab_table,\n",
        "      token_out_type=tf.int64)\n",
        "  segments = [tokenizer.tokenize(text).merge_dims(\n",
        "      1, -1) for text in (text_a, text_b)]\n",
        "\n",
        "  # Truncate inputs to a maximum length.\n",
        "  trimmer = text.RoundRobinTrimmer(max_seq_length=6)\n",
        "  trimmed_segments = trimmer.trim(segments)\n",
        "\n",
        "  # Combine segments, get segment ids and add special tokens.\n",
        "  segments_combined, segment_ids = text.combine_segments(\n",
        "      trimmed_segments,\n",
        "      start_of_sequence_id=_START_TOKEN,\n",
        "      end_of_segment_id=_END_TOKEN)\n",
        "\n",
        "  # Apply dynamic masking task.\n",
        "  masked_input_ids, masked_lm_positions, masked_lm_ids = (\n",
        "      text.mask_language_model(\n",
        "        segments_combined,\n",
        "        random_selector,\n",
        "        mask_values_chooser,\n",
        "      )\n",
        "  )\n",
        "\n",
        "  # Prepare and pad combined segment inputs\n",
        "  input_word_ids, input_mask = text.pad_model_inputs(\n",
        "    masked_input_ids, max_seq_length=_MAX_SEQ_LEN)\n",
        "  input_type_ids, _ = text.pad_model_inputs(\n",
        "    segment_ids, max_seq_length=_MAX_SEQ_LEN)\n",
        "\n",
        "  # Prepare and pad masking task inputs\n",
        "  masked_lm_positions, masked_lm_weights = text.pad_model_inputs(\n",
        "    masked_lm_positions, max_seq_length=_MAX_PREDICTIONS_PER_BATCH)\n",
        "  masked_lm_ids, _ = text.pad_model_inputs(\n",
        "    masked_lm_ids, max_seq_length=_MAX_PREDICTIONS_PER_BATCH)\n",
        "\n",
        "  model_inputs = {\n",
        "      \"input_word_ids\": input_word_ids,\n",
        "      \"input_mask\": input_mask,\n",
        "      \"input_type_ids\": input_type_ids,\n",
        "      \"masked_lm_ids\": masked_lm_ids,\n",
        "      \"masked_lm_positions\": masked_lm_positions,\n",
        "      \"masked_lm_weights\": masked_lm_weights,\n",
        "  }\n",
        "  return model_inputs"
      ],
      "metadata": {
        "id": "SGi6DzZ_HvKn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = (\n",
        "    tf.data.Dataset.from_tensors(examples)\n",
        "    .map(functools.partial(bert_pretrain_preprocess, lookup_table))\n",
        ")\n",
        "\n",
        "next(iter(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HCbq3bJHxzD",
        "outputId": "a112704d-d6e8-44f2-c2b0-bd47bcc37559"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_word_ids': <tf.Tensor: shape=(2, 8), dtype=int64, numpy=\n",
              " array([[ 3, 22,  1,  8,  4, 16,  5, 19],\n",
              "        [ 3, 18, 12, 15,  4, 21,  1, 30]])>,\n",
              " 'input_mask': <tf.Tensor: shape=(2, 8), dtype=int64, numpy=\n",
              " array([[1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1]])>,\n",
              " 'input_type_ids': <tf.Tensor: shape=(2, 8), dtype=int64, numpy=\n",
              " array([[0, 0, 0, 0, 0, 1, 1, 1],\n",
              "        [0, 0, 0, 0, 0, 1, 1, 1]])>,\n",
              " 'masked_lm_ids': <tf.Tensor: shape=(2, 5), dtype=int64, numpy=\n",
              " array([[ 9, 24,  0,  0,  0],\n",
              "        [12, 28,  0,  0,  0]])>,\n",
              " 'masked_lm_positions': <tf.Tensor: shape=(2, 5), dtype=int64, numpy=\n",
              " array([[2, 3, 0, 0, 0],\n",
              "        [2, 6, 0, 0, 0]])>,\n",
              " 'masked_lm_weights': <tf.Tensor: shape=(2, 5), dtype=int64, numpy=\n",
              " array([[1, 1, 0, 0, 0],\n",
              "        [1, 1, 0, 0, 0]])>}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FeX3xbI9HzHV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}