{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepOnKHATT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OXV2NEE2gEN"
      },
      "source": [
        "---\n",
        "**NOTE** \\\n",
        "After installing tensorflow 1.5, you need to restart runtime. You will be asked to do so by clicking button upon installation completion.\n",
        "This notebook is developed to run on Colab.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAoNBd2OoGBV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e4588bd-dd3e-4832-ca23-04cb75b45cb6"
      },
      "source": [
        "!pip3 install tensorflow==1.15.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==1.15.0\n",
            "  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3 MB 20 kB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.17.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.21.6)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.5 MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 67.6 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 95.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.47.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.37.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.14.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.8.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.0) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=d131bb41c284af6911146e14cdb8bf0226432cf81de07e0732c455d6e269e2a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pu-umFpU3zUX",
        "outputId": "008c10ab-e9a5-4e20-e306-37753d7cb54c"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay5so5B6IO4r",
        "outputId": "6bee766b-5bfc-446d-fd29-6a5c145f80cc"
      },
      "source": [
        "!git clone https://github.com/fakhralwajih/DeepOnKHATT.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DeepOnKHATT'...\n",
            "remote: Enumerating objects: 116, done.\u001b[K\n",
            "remote: Total 116 (delta 0), reused 0 (delta 0), pack-reused 116\u001b[K\n",
            "Receiving objects: 100% (116/116), 2.75 MiB | 23.27 MiB/s, done.\n",
            "Resolving deltas: 100% (38/38), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuED-IaVIgkz"
      },
      "source": [
        "# change dir to DeepOnKHATT dir\n",
        "import os\n",
        "os.chdir('DeepOnKHATT')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7P-j-4WaPLU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4ddce99-f227-4e91-c19a-22745f8ec5ea"
      },
      "source": [
        "#download pre-trained models\n",
        "!gdown --id 1-YAltfi_4Klvu_-f72iSkHboM46-iH_t --output lm/trie\n",
        "!gdown --id 1MqhnAcXMwT_nq_z-01CRhWKLYJYZBa1A --output lm/lm.binary\n",
        "!gdown --id  1Z_gzzWVjskv_1JqErGuz8ZVfCSNaC3VY --output models/models.zip\n",
        "!unzip models/models.zip -d models/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-YAltfi_4Klvu_-f72iSkHboM46-iH_t\n",
            "To: /content/DeepOnKHATT/lm/trie\n",
            "100% 14.0M/14.0M [00:00<00:00, 114MB/s] \n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1MqhnAcXMwT_nq_z-01CRhWKLYJYZBa1A\n",
            "To: /content/DeepOnKHATT/lm/lm.binary\n",
            "100% 1.07G/1.07G [00:07<00:00, 137MB/s] \n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Z_gzzWVjskv_1JqErGuz8ZVfCSNaC3VY\n",
            "To: /content/DeepOnKHATT/models/models.zip\n",
            "100% 344M/344M [00:02<00:00, 128MB/s]\n",
            "Archive:  models/models.zip\n",
            "  inflating: models/model.ckpt-14.meta  \n",
            "  inflating: models/model.ckpt-14.data-00000-of-00001  \n",
            "  inflating: models/model.ckpt-14.index  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_8U5bRxmDG9",
        "outputId": "833d0569-479a-49a7-bd62-799b88231409"
      },
      "source": [
        "#install decoder \n",
        "!pip3 install ds_ctcdecoder==0.6.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ds_ctcdecoder==0.6.1\n",
            "  Downloading ds_ctcdecoder-0.6.1-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from ds_ctcdecoder==0.6.1) (1.21.6)\n",
            "Installing collected packages: ds-ctcdecoder\n",
            "Successfully installed ds-ctcdecoder-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVby5o4sJOh4"
      },
      "source": [
        "from features.feature import calculate_feature_vector_sequence \n",
        "from features.preprocessing import preprocess_handwriting\n",
        "from rnn import BiRNN as BiRNN_model\n",
        "from datasets import pad_sequences,sparse_tuple_from ,handwriting_to_input_vector\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBu43UrasYS6"
      },
      "source": [
        "import argparse\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from ds_ctcdecoder import ctc_beam_search_decoder, Scorer\n",
        "from text import Alphabet,get_arabic_letters,decodex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R40OahqYTsXr"
      },
      "source": [
        "letters_ar=get_arabic_letters()\n",
        "alphabet = Alphabet('alphabet.txt')\n",
        "#convert this to funcation\n",
        "mapping={}\n",
        "with open('arabic_mapping.txt','r', encoding='utf-8') as inf:\n",
        "    for line in inf:\n",
        "        key,val=line.split('\\t')\n",
        "        mapping[key]=val.strip()\n",
        "mapping[' ']=' '\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oWXqRfOS2WW"
      },
      "source": [
        "## imports for writing canvas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G3uFlPoRCoU"
      },
      "source": [
        "from IPython.display import HTML, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnNUt7IFpAN-"
      },
      "source": [
        "from configparser import ConfigParser\n",
        "config_file='neural_network.ini'\n",
        "model_path='models/model.ckpt-14'\n",
        "parser = ConfigParser()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN73hDLVXQif"
      },
      "source": [
        "parser.read('neural_network.ini')\n",
        "config_header='nn'       \n",
        "network_type = parser.get(config_header , 'network_type')\n",
        "n_context = parser.getint(config_header, 'n_context') \n",
        "n_input = parser.getint(config_header, 'n_input')\n",
        "beam_search_decoder = parser.get(config_header, 'beam_search_decoder')        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eU5OSIJpXUh"
      },
      "source": [
        "#LM setting\n",
        "config_header='lm' \n",
        "lm_alpha=parser.getfloat(config_header , 'lm_alpha')\n",
        "lm_beta=parser.getfloat(config_header , 'lm_beta')\n",
        "beam_width=parser.getint(config_header , 'beam_width')\n",
        "cutoff_prob=parser.getfloat(config_header , 'cutoff_prob')\n",
        "cutoff_top_n= parser.getint(config_header , 'cutoff_top_n')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2vuzRk5Xt8r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "531bdf2c-390f-4635-f463-4fbcae73b471"
      },
      "source": [
        "conf_path='neural_network.ini'\n",
        "input_tensor = tf.placeholder(tf.float32, [None, None, n_input + (2 * n_input * n_context)], name='input')    \n",
        "seq_length = tf.placeholder(tf.int32, [None], name='seq_length')\n",
        "logits, summary_op = BiRNN_model(conf_path,input_tensor,tf.to_int64(seq_length),n_input,n_context)\n",
        "#if you need to try greedy decoder without LM\n",
        "# decoded, log_prob = ctc_ops.ctc_greedy_decoder(logits, seq_length, merge_repeated=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-14-449b83e3e51b>:4: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/DeepOnKHATT/rnn.py:18: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/DeepOnKHATT/rnn.py:226: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /content/DeepOnKHATT/rnn.py:228: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/DeepOnKHATT/rnn.py:259: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /content/DeepOnKHATT/rnn.py:283: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/DeepOnKHATT/rnn.py:319: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC1_jNJcZICI"
      },
      "source": [
        "lm_binary_path='lm/lm.binary'\n",
        "lm_trie_path='lm/trie'\n",
        "\n",
        "scorer=None\n",
        "scorer = Scorer(lm_alpha, lm_beta,lm_binary_path, lm_trie_path,alphabet)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLoNGG3CbO2t"
      },
      "source": [
        "config_file='neural_network.ini'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xq9TqgeIpYZh",
        "outputId": "d72be44e-e4e2-4a84-ca88-f981954fcfff"
      },
      "source": [
        "saver = tf.train.Saver()\n",
        "# create the session\n",
        "sess = tf.Session()\n",
        "saver.restore(sess, 'models/model.ckpt-14')\n",
        "print('Model restored') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from models/model.ckpt-14\n",
            "Model restored\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zFfWNE4Y0F4"
      },
      "source": [
        "canvas_html = \"\"\"\n",
        "<canvas id=\"mycanvas\" width=%d height=%d style=\"border:1px solid #000000;\"></canvas>\n",
        " <br />\n",
        "<button>Recoginize</button>\n",
        "\n",
        "<script>\n",
        "var canvas = document.getElementById('mycanvas')\n",
        "var ctx = canvas.getContext('2d')\n",
        "ctx.lineWidth = %d\n",
        "ctx.canvas.style.touchAction = \"none\";\n",
        "var button = document.querySelector('button')\n",
        "var mouse = {x: 0, y: 0}\n",
        "var points=[]\n",
        "\n",
        "canvas.addEventListener('pointermove', function(e) {\n",
        "  mouse.x = e.pageX - this.offsetLeft\n",
        "  mouse.y = e.pageY - this.offsetTop\n",
        "})\n",
        "canvas.onpointerdown = ()=>{\n",
        "  ctx.beginPath()\n",
        "  ctx.moveTo(mouse.x, mouse.y)\n",
        "  \n",
        "  canvas.addEventListener('pointermove', onPaint)\n",
        "}\n",
        "canvas.onpointerup = ()=>{\n",
        "  canvas.removeEventListener('pointermove', onPaint)\n",
        "  points.pop()\n",
        "  points.push([mouse.x,mouse.y,1])\n",
        "}\n",
        "var onPaint = ()=>{\n",
        "  ctx.lineTo(mouse.x, mouse.y)\n",
        "  ctx.stroke()\n",
        "  points.push([mouse.x,mouse.y,0])\n",
        "}\n",
        "var data = new Promise(resolve=>{\n",
        "  button.onclick = ()=>{\n",
        "    resolve(canvas.toDataURL('image/png'))\n",
        "  }\n",
        "})\n",
        "</script>\n",
        "\"\"\"\n",
        "def draw(filename='drawing.png', w=900, h=200, line_width=1):\n",
        "  display(HTML(canvas_html % (w, h, line_width)))\n",
        "  data = eval_js(\"data\")\n",
        "  points=eval_js(\"points\")\n",
        "  # strokes = Utils.Rearrange(strokes, 20);\n",
        "  points=np.array(points)\n",
        "\n",
        "  # points=rearrange(points)\n",
        "\n",
        "\n",
        "  # print(\"Points before pre\",points.shape)\n",
        "  NORM_ARGS = [\"origin\",\"filp_h\",\"smooth\", \"slope\", \"resample\", \"slant\", \"height\"]\n",
        "  FEAT_ARGS = [\"x_cor\",\"y_cor\",\"penup\",\"dir\", \"curv\", \"vic_aspect\", \"vic_curl\", \"vic_line\", \"vic_slope\", \"bitmap\"]\n",
        "  # print(\"Normalizing trajectory...\")\n",
        "  traj = preprocess_handwriting(points, NORM_ARGS)\n",
        "  # print(traj)\n",
        "  # print(\"Calculating feature vector sequence...\")\n",
        "  feat_seq_mat = calculate_feature_vector_sequence(traj, FEAT_ARGS)\n",
        "  feat_seq_mat=feat_seq_mat.astype('float32')\n",
        "  feat_seq_mat.shape\n",
        "\n",
        "  data = []\n",
        "\n",
        "  train_input=handwriting_to_input_vector(feat_seq_mat,20,9)\n",
        "  train_input = train_input.astype('float32')\n",
        "\n",
        "  data.append(train_input)\n",
        "  # data_len\n",
        "\n",
        "  data = np.asarray(data)\n",
        "  # data_len = np.asarray(train_input)\n",
        "\n",
        "\n",
        "  # Pad input to max_time_step of this batch\n",
        "  source, source_lengths = pad_sequences(data)\n",
        "  my_logits=sess.run(logits, feed_dict={\n",
        "                  input_tensor: source,                    \n",
        "                  seq_length: source_lengths}\n",
        "              )\n",
        "  my_logits = np.squeeze(my_logits)\n",
        "  maxT, _ = my_logits.shape # dim0=t, dim1=c\n",
        "\t\n",
        "            # apply softmax\n",
        "  res = np.zeros(my_logits.shape)\n",
        "  for t in range(maxT):\n",
        "      y = my_logits[t, :]\n",
        "      e = np.exp(y)\n",
        "      s = np.sum(e)\n",
        "      res[t, :] = e / s\n",
        "            \n",
        "  decoded = ctc_beam_search_decoder(res, alphabet, beam_width,\n",
        "                                  scorer=scorer, cutoff_prob=cutoff_prob,\n",
        "                                  cutoff_top_n=cutoff_top_n)\n",
        "\n",
        "  print(\"Result : \"+decodex(decoded[0][1],mapping))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Cj527QnPodk"
      },
      "source": [
        "**Note**  \\\n",
        "The next cell, you can run multiple times as you wish. You may want to write many samples. \\\n",
        "All the above cells should run only once. \\\n",
        "\n",
        "Run the cell and write on the canvas while the cell is running. Then, click on \"Recoginize\" button to get the recognition result.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1Uvk3xxp3Bj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "b3dee8cd-0279-43d5-8e21-c26901216397"
      },
      "source": [
        "draw()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<canvas id=\"mycanvas\" width=900 height=200 style=\"border:1px solid #000000;\"></canvas>\n",
              " <br />\n",
              "<button>Recoginize</button>\n",
              "\n",
              "<script>\n",
              "var canvas = document.getElementById('mycanvas')\n",
              "var ctx = canvas.getContext('2d')\n",
              "ctx.lineWidth = 1\n",
              "ctx.canvas.style.touchAction = \"none\";\n",
              "var button = document.querySelector('button')\n",
              "var mouse = {x: 0, y: 0}\n",
              "var points=[]\n",
              "\n",
              "canvas.addEventListener('pointermove', function(e) {\n",
              "  mouse.x = e.pageX - this.offsetLeft\n",
              "  mouse.y = e.pageY - this.offsetTop\n",
              "})\n",
              "canvas.onpointerdown = ()=>{\n",
              "  ctx.beginPath()\n",
              "  ctx.moveTo(mouse.x, mouse.y)\n",
              "  \n",
              "  canvas.addEventListener('pointermove', onPaint)\n",
              "}\n",
              "canvas.onpointerup = ()=>{\n",
              "  canvas.removeEventListener('pointermove', onPaint)\n",
              "  points.pop()\n",
              "  points.push([mouse.x,mouse.y,1])\n",
              "}\n",
              "var onPaint = ()=>{\n",
              "  ctx.lineTo(mouse.x, mouse.y)\n",
              "  ctx.stroke()\n",
              "  points.push([mouse.x,mouse.y,0])\n",
              "}\n",
              "var data = new Promise(resolve=>{\n",
              "  button.onclick = ()=>{\n",
              "    resolve(canvas.toDataURL('image/png'))\n",
              "  }\n",
              "})\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result : احسان\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KT69P5KQ09D"
      },
      "source": [
        "The above canvas was tested on PC mouse and S pen (samsung tablet) and works well with S pen."
      ]
    }
  ]
}